{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Role Title and Role Code are similar based on pandas\n",
    "*Instead of using hashing, can consider cantor(m,n) = 1/2 * (m+n)(m+n+1)+m. Beware of hash collision\n",
    "*PCA / SVD are more suited for continuous values. For discrete variables, consider using MCA\n",
    "1. Feature Extraction - Using Genetic Algorithm / Greedy Algorithm [sklearn.feature_selection.RFE, RFECV , Gradient Boosting\n",
    "2. Try using Stacked Classifier \n",
    "  * np.mean\n",
    "  * weighted mean\n",
    "  * jaccard score\n",
    "  * pass the results from each classifer into another RF / Linear Regression\n",
    "3. Data Exploratory - Find if train has more classes compared to test ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pivottablejs import pivot_ui\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt  \n",
    "from ipywidgets import widgets\n",
    "import numpy as np\n",
    "from sklearn import (metrics, cross_validation, linear_model, preprocessing)\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import ensemble\n",
    "from itertools import combinations\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sb.set(style=\"ticks\", color_codes=True)\n",
    "df = pd.read_csv('train.csv')\n",
    "dft = pd.read_csv('test.csv')\n",
    "#g = sb.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Observation Only\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTION</th>\n",
       "      <th>RESOURCE</th>\n",
       "      <th>MGR_ID</th>\n",
       "      <th>ROLE_ROLLUP_1</th>\n",
       "      <th>ROLE_ROLLUP_2</th>\n",
       "      <th>ROLE_DEPTNAME</th>\n",
       "      <th>ROLE_TITLE</th>\n",
       "      <th>ROLE_FAMILY_DESC</th>\n",
       "      <th>ROLE_FAMILY</th>\n",
       "      <th>ROLE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32769</td>\n",
       "      <td>32769</td>\n",
       "      <td>32769</td>\n",
       "      <td>32769</td>\n",
       "      <td>32769</td>\n",
       "      <td>32769</td>\n",
       "      <td>32769</td>\n",
       "      <td>32769</td>\n",
       "      <td>32769</td>\n",
       "      <td>32769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>7518</td>\n",
       "      <td>4243</td>\n",
       "      <td>128</td>\n",
       "      <td>177</td>\n",
       "      <td>449</td>\n",
       "      <td>343</td>\n",
       "      <td>2358</td>\n",
       "      <td>67</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1</td>\n",
       "      <td>4675</td>\n",
       "      <td>770</td>\n",
       "      <td>117961</td>\n",
       "      <td>118300</td>\n",
       "      <td>117878</td>\n",
       "      <td>118321</td>\n",
       "      <td>117906</td>\n",
       "      <td>290919</td>\n",
       "      <td>118322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>30872</td>\n",
       "      <td>839</td>\n",
       "      <td>152</td>\n",
       "      <td>21407</td>\n",
       "      <td>4424</td>\n",
       "      <td>1135</td>\n",
       "      <td>4649</td>\n",
       "      <td>6896</td>\n",
       "      <td>10980</td>\n",
       "      <td>4649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACTION  RESOURCE  MGR_ID  ROLE_ROLLUP_1  ROLE_ROLLUP_2  ROLE_DEPTNAME  \\\n",
       "count    32769     32769   32769          32769          32769          32769   \n",
       "unique       2      7518    4243            128            177            449   \n",
       "top          1      4675     770         117961         118300         117878   \n",
       "freq     30872       839     152          21407           4424           1135   \n",
       "\n",
       "        ROLE_TITLE  ROLE_FAMILY_DESC  ROLE_FAMILY  ROLE_CODE  \n",
       "count        32769             32769        32769      32769  \n",
       "unique         343              2358           67        343  \n",
       "top         118321            117906       290919     118322  \n",
       "freq          4649              6896        10980       4649  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(df['RESOURCE'].value_counts())\n",
    "#df['RESOURCE'].plot.hist(bins=7518)\n",
    "\n",
    "#dfc = df.iloc[:,1:10] \n",
    "dfc = df.iloc[:,:]\n",
    "for col in df.columns:\n",
    "  dfc[col] = df[col].astype('category')\n",
    "\n",
    "dfc.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Observation Only\n",
    "#test = pd.pivot_table(dfc,index=['ROLE_TITLE','ROLE_CODE'],aggfunc='count',dropna=True)\n",
    "#dfc.pivot_table(index='ROLE_TITLE',aggfunc=lambda x:len(x.unique()))\n",
    "mult = {}\n",
    "for c in df.columns:\n",
    "    temp = df.pivot_table(index=c,aggfunc=lambda x:len(x.unique()),fill_value=0).apply(np.max)\n",
    "    mult[c] = temp\n",
    "\n",
    "multpd = pd.DataFrame(mult)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_results(predictions, filename):\n",
    "    \"\"\"Given a vector of predictions, save results in CSV format.\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"id,ACTION\\n\")\n",
    "        for i, pred in enumerate(predictions):\n",
    "            f.write(\"%d,%f\\n\" % (i + 1, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cantor(pairs):\n",
    "    result2 = 0.5 * (pairs[0] + pairs[1]) * (pairs[0] + pairs[1] +1) + pairs[1]\n",
    "    if(len(pairs) == 2): \n",
    "        return result2\n",
    "    if(len(pairs) == 3 ):\n",
    "        result3 = 0.5 * (result2 + pairs[2]) * (result2 + pairs[2] +1) + pairs[2]\n",
    "        return result3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert from dataframe to np.array\n",
    "y = np.ravel(df.iloc[:,:1])\n",
    "X = np.array(df.iloc[:,1:9])\n",
    "X_test = np.array(dft.iloc[:,1:9])\n",
    "header = list(df.columns[1:])\n",
    "\n",
    "data = np.vstack((X,X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Combinations\n",
      "(91690, 36)\n",
      "False\n",
      "0\n",
      "194537644783.0\n",
      "3 Combinations\n",
      "(91690, 92)\n",
      "False\n",
      "0\n",
      "1.892247063879666e+22\n"
     ]
    }
   ],
   "source": [
    "# yc = combinations(range(n),2)\n",
    "# to view all the combinations\n",
    "# list(yc) \n",
    "\n",
    "#train data[:32769,:]\n",
    "#test data[32769:,:]\n",
    "#tuple is used here so that the result is hashable\n",
    "\n",
    "test_offset = 32769\n",
    "# Get Combinations of 2 features \n",
    "for indices in combinations(range(8),2):\n",
    "    #data = np.column_stack((data,list(ctypes.c_size_t(hash(tuple(v))).value for v in data[:,indices]))) \n",
    "    #data = np.column_stack((data,list(np.uint64(hash(tuple(v))) for v in data[:,indices]))) \n",
    "    #data = np.column_stack((data,list(hash(tuple(v)) for v in data[:,indices]))) \n",
    "    data = np.column_stack((data,list(cantor(tuple(v)) for v in data[:,indices]))) \n",
    "    #a,b = indices\n",
    "    #header.append(header[a] +\"&\"+ header[b])\n",
    "print('2 Combinations')\n",
    "print(data.shape)\n",
    "print(np.any(data < 0))\n",
    "print(np.ndarray.min(data))\n",
    "print(np.ndarray.max(data))\n",
    "    \n",
    "# Get Combinations of 3 features \n",
    "for indices in combinations(range(8),3):\n",
    "    data = np.column_stack((data,list(cantor(tuple(v)) for v in data[:,indices]))) \n",
    "    \n",
    "#Check loaded correctly with non-zero elements    \n",
    "print('3 Combinations')\n",
    "print(data.shape)\n",
    "print(np.any(data < 0))\n",
    "print(np.ndarray.min(data))\n",
    "print(np.ndarray.max(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0\n",
      "81232\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Simplify the encoding. Probably not essential. Could possibly improve performance\n",
    "# Vertical Stacking is required so that all the features are captured. There might be some features in test set not in train set\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "data_e = []\n",
    "# To perform column wise operations, use Transpose function\n",
    "for i in data.T:\n",
    "    le.fit(i)\n",
    "    data_e.append(le.transform(i))\n",
    "\n",
    "data = np.asarray(data_e).T\n",
    "\n",
    "print(np.any(data < 0))\n",
    "print(np.ndarray.min(data))\n",
    "print(np.ndarray.max(data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #Code to help Visualize what the algorithm is doing \n",
    "# t_data = []\n",
    "# test_data = np.array([[1,2,3,4],[1,2,2,0],[1,2,3,4],[1,4,5,6],[2,3,4,5]])\n",
    "# print(test_data.shape)\n",
    "\n",
    "# #if the combination of categories are the same, they will be hashed to the same value. Eg 1 row with (0,1,0) will have same \n",
    "# #hash value of another row with (0,1,0)\n",
    "# for indices in combinations(range(4),2):\n",
    "#     t_data.append(hash(tuple(v)) for v in test_data[:,indices])\n",
    "#     #print(v for v in test_data[:,indices])\n",
    "#     print(indices)\n",
    "    \n",
    "# #Comparison 1 - Combinations are (0,1),(0,2),(0,3),(1,2),(1,3),(2,3)\n",
    "# # for v in test_data[:,(0,1)]:\n",
    "# #   print(hash(tuple(v)))\n",
    "\n",
    "# #Comparison 2 - t_data[0] corresponds to (0,1)\n",
    "# #tuple(t_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = preprocessing.OneHotEncoder(dtype=np.uint32)\n",
    "# we want to encode the category IDs encountered both in\n",
    "# the training and the test set, so we fit the encoder on both\n",
    "encoder.fit(data)\n",
    "X = encoder.transform(data[:test_offset,:])\n",
    "X_test = encoder.transform(data[test_offset:,:])\n",
    "\n",
    "# encoder = preprocessing.OneHotEncoder()\n",
    "# encoder.fit(data)\n",
    "# X = encoder.transform(X)\n",
    "# X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC (fold 1/10): 0.883359\n",
      "AUC (fold 2/10): 0.881408\n",
      "AUC (fold 3/10): 0.891638\n",
      "AUC (fold 4/10): 0.899944\n",
      "AUC (fold 5/10): 0.883712\n",
      "AUC (fold 6/10): 0.889287\n",
      "AUC (fold 7/10): 0.874977\n",
      "AUC (fold 8/10): 0.884113\n",
      "AUC (fold 9/10): 0.882565\n",
      "AUC (fold 10/10): 0.892604\n",
      "Mean AUC: 0.886361\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "mean_auc = 0.0\n",
    "\n",
    "n = 10  # repeat the CV procedure 10 times to get more precise results\n",
    "model = linear_model.LogisticRegression(C=1)\n",
    "#model = BernoulliNB(alpha=0.005)\n",
    "for i in range(n):\n",
    "    # for each iteration, randomly hold out 20% of the data as CV set\n",
    "    X_train, X_cv, y_train, y_cv = cross_validation.train_test_split(X, y, test_size=.20, random_state=i*SEED)\n",
    "\n",
    "    # if you want to perform feature selection / hyperparameter\n",
    "    # optimization, this is where you want to do it\n",
    "\n",
    "    # train model and make predictions\n",
    "    model.fit(X_train, y_train) \n",
    "    preds = model.predict_proba(X_cv)[:, 1]\n",
    "\n",
    "    # compute AUC metric for this CV fold\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_cv, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print(\"AUC (fold %d/%d): %f\" % (i + 1, n, roc_auc))\n",
    "    mean_auc += roc_auc\n",
    "\n",
    "print(\"Mean AUC: %f\" % (mean_auc/n))\n",
    "\n",
    "# === Predictions === #\n",
    "# When making predictions, retrain the model on the whole training set\n",
    "model.fit(X, y)\n",
    "preds = model.predict_proba(X_test)[:, 1]\n",
    "save_results(preds, \"submit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = linear_model.LogisticRegression(C=1)\n",
    "selector = RFE(estimator)\n",
    "selector = selector.fit(X, y)\n",
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Numpy Operations\n",
    "# print(np.fromiter(t_data[0],np.int32))\n",
    "# print(np.fromiter(t_data[1],np.int32))\n",
    "# print(np.fromiter(t_data[2],np.int32))\n",
    "# print(np.fromiter(t_data[3],np.int32))\n",
    "# print(np.fromiter(t_data[4],np.int32))\n",
    "# print(np.fromiter(t_data[5],np.int32))\n",
    "\n",
    "# Convert to numpy array - Use np.array(list)\n",
    "# for i in nparray - iterate through rows\n",
    "# for i in nparray.T - iterate through columns\n",
    "# Initialize np.zeros(5)\n",
    "\n",
    "# To view generator operators (Use list,tuples)\n",
    "# for i,j in enumerate(t_data):\n",
    "#     #lst_array[i] = np.array(list(j))\n",
    "#     lst_array[i] = np.fromiter(j,np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC = Logistic Regression returns the probability that a certain input features would be in a certain class\n",
    "ROC curve visualizaes all possible thresholds\n",
    "Misclassification rate is error rate for a single threshold\n",
    "\n",
    "\n",
    "Attempt with original features : Public : 0.88515, Private : 0.88205\n",
    "Attempt with original features + combination of 2 : Public : 0.90141, Private 0.89582 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
