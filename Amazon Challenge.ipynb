{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Role Title and Role Code are similar based on pandas\n",
    "*Instead of using hashing, can consider cantor(m,n) = 1/2 * (m+n)(m+n+1)+m. Beware of hash collision\n",
    "*PCA / SVD are more suited for continuous values. For discrete variables, consider using MCA\n",
    "1. Feature Extraction - Using Genetic Algorithm / Greedy Algorithm [sklearn.feature_selection.RFE, RFECV , Gradient Boosting\n",
    "2. Try using Stacked Classifier \n",
    "  * np.mean\n",
    "  * weighted mean\n",
    "  * jaccard score\n",
    "  * pass the results from each classifer into another RF / Linear Regression\n",
    "3. Data Exploratory - Find if train has more classes compared to test ? \n",
    "4. Try to run on Spark\n",
    "5. Stratified K Fold Cross Validation\n",
    "6. Try with less features to do on Random Forest Classifier\n",
    "7. Try to use only selected Hot Encoded features for random forest classifier\n",
    "8. Use GridSearchCV to optimize Logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#inside a ipython/nb session\n",
    "# %store encoder\n",
    "# %store data\n",
    "# %store X\n",
    "# %store X_test\n",
    "# %store y\n",
    "# %store features\n",
    "# %store header\n",
    "# %store test_offset\n",
    "\n",
    "%store -r encoder\n",
    "%store -r data\n",
    "%store -r X\n",
    "%store -r X_test\n",
    "%store -r y\n",
    "%store -r features\n",
    "%store -r header\n",
    "%store -r test_offset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pivottablejs import pivot_ui\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt  \n",
    "from ipywidgets import widgets\n",
    "import numpy as np\n",
    "from sklearn import (metrics, cross_validation, linear_model, preprocessing)\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import (GradientBoostingClassifier)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import ensemble\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sb.set(style=\"ticks\", color_codes=True)\n",
    "df = pd.read_csv('train.csv')\n",
    "dft = pd.read_csv('test.csv')\n",
    "#g = sb.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Observation Only\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#len(df['RESOURCE'].value_counts())\n",
    "#df['RESOURCE'].plot.hist(bins=7518)\n",
    "\n",
    "#dfc = df.iloc[:,1:10] \n",
    "dfc = df.iloc[:,:]\n",
    "for col in df.columns:\n",
    "  dfc[col] = df[col].astype('category')\n",
    "\n",
    "dfc.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Observation Only\n",
    "#test = pd.pivot_table(dfc,index=['ROLE_TITLE','ROLE_CODE'],aggfunc='count',dropna=True)\n",
    "#dfc.pivot_table(index='ROLE_TITLE',aggfunc=lambda x:len(x.unique()))\n",
    "mult = {}\n",
    "for c in df.columns:\n",
    "    temp = df.pivot_table(index=c,aggfunc=lambda x:len(x.unique()),fill_value=0).apply(np.max)\n",
    "    mult[c] = temp\n",
    "\n",
    "multpd = pd.DataFrame(mult)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_results(predictions, filename):\n",
    "    \"\"\"Given a vector of predictions, save results in CSV format.\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"id,ACTION\\n\")\n",
    "        for i, pred in enumerate(predictions):\n",
    "            f.write(\"%d,%f\\n\" % (i + 1, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cantor(pairs):\n",
    "    result2 = 0.5 * (pairs[0] + pairs[1]) * (pairs[0] + pairs[1] +1) + pairs[1]\n",
    "    if(len(pairs) == 2): \n",
    "        return result2\n",
    "    if(len(pairs) == 3 ):\n",
    "        result3 = 0.5 * (result2 + pairs[2]) * (result2 + pairs[2] +1) + pairs[2]\n",
    "        return result3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert from dataframe to np.array\n",
    "y = np.ravel(df.iloc[:,:1])\n",
    "X = np.array(df.iloc[:,1:9])\n",
    "X_test = np.array(dft.iloc[:,1:9])\n",
    "header = list(df.columns[1:])\n",
    "\n",
    "data = np.vstack((X,X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Combinations\n",
      "(91690, 36)\n",
      "False\n",
      "0.0\n",
      "194537644783.0\n",
      "3 Combinations\n",
      "(91690, 92)\n",
      "False\n",
      "0.0\n",
      "1.89224706388e+22\n"
     ]
    }
   ],
   "source": [
    "# yc = combinations(range(n),2)\n",
    "# to view all the combinations\n",
    "# list(yc) \n",
    "\n",
    "#train data[:32769,:]\n",
    "#test data[32769:,:]\n",
    "#tuple is used here so that the result is hashable\n",
    "\n",
    "test_offset = 32769\n",
    "# Get Combinations of 2 features \n",
    "for indices in combinations(range(8),2):\n",
    "    #data = np.column_stack((data,list(ctypes.c_size_t(hash(tuple(v))).value for v in data[:,indices]))) \n",
    "    #data = np.column_stack((data,list(np.uint64(hash(tuple(v))) for v in data[:,indices]))) \n",
    "    #data = np.column_stack((data,list(hash(tuple(v)) for v in data[:,indices]))) \n",
    "    data = np.column_stack((data,list(cantor(tuple(v)) for v in data[:,indices]))) \n",
    "    a,b = indices\n",
    "    header.append(header[a] +\"&\"+ header[b])\n",
    "print('2 Combinations')\n",
    "print(data.shape)\n",
    "print(np.any(data < 0))\n",
    "print(np.ndarray.min(data))\n",
    "print(np.ndarray.max(data))\n",
    "    \n",
    "# Get Combinations of 3 features \n",
    "for indices in combinations(range(8),3):\n",
    "    data = np.column_stack((data,list(cantor(tuple(v)) for v in data[:,indices]))) \n",
    "    a,b,c = indices\n",
    "    header.append(header[a] +\"&\"+ header[b]+ \"&\" + header[c])\n",
    "\n",
    "    \n",
    "#Check loaded correctly with non-zero elements    \n",
    "print('3 Combinations')\n",
    "print(data.shape)\n",
    "print(np.any(data < 0))\n",
    "print(np.ndarray.min(data))\n",
    "print(np.ndarray.max(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0\n",
      "81232\n"
     ]
    }
   ],
   "source": [
    "# Simplify the encoding. Probably not essential. Could possibly improve performance\n",
    "# Vertical Stacking is required so that all the features are captured. There might be some features in test set not in train set\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "data_e = []\n",
    "# To perform column wise operations, use Transpose function\n",
    "for i in data.T:\n",
    "    le.fit(i)\n",
    "    data_e.append(le.transform(i))\n",
    "\n",
    "data = np.asarray(data_e).T\n",
    "\n",
    "print(np.any(data < 0))\n",
    "print(np.ndarray.min(data))\n",
    "print(np.ndarray.max(data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #Code to help Visualize what the algorithm is doing \n",
    "# t_data = []\n",
    "# test_data = np.array([[1,2,3,4],[1,2,2,0],[1,2,3,4],[1,4,5,6],[2,3,4,5]])\n",
    "# print(test_data.shape)\n",
    "\n",
    "# #if the combination of categories are the same, they will be hashed to the same value. Eg 1 row with (0,1,0) will have same \n",
    "# #hash value of another row with (0,1,0)\n",
    "# for indices in combinations(range(4),2):\n",
    "#     t_data.append(hash(tuple(v)) for v in test_data[:,indices])\n",
    "#     #print(v for v in test_data[:,indices])\n",
    "#     print(indices)\n",
    "    \n",
    "# #Comparison 1 - Combinations are (0,1),(0,2),(0,3),(1,2),(1,3),(2,3)\n",
    "# # for v in test_data[:,(0,1)]:\n",
    "# #   print(hash(tuple(v)))\n",
    "\n",
    "# #Comparison 2 - t_data[0] corresponds to (0,1)\n",
    "# #tuple(t_data[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32769, 1595040)\n",
      "(58921, 1595040)\n",
      "Total One Hot Features [      0       1       2 ..., 1595037 1595038 1595039]\n",
      "Boundaries of each Feature 93 [      0    7518   12431   12561   12744   13220   13581   16532   16600\n",
      "   75768   90451  109920  137769  170899  218323  237208  242455  247918\n",
      "  253962  263393  273915  280609  280803  282114  283908  288133  288987\n",
      "  290556  293042  298050  299228  302623  308267  310094  313899  314260\n",
      "  317513  377513  438473  502060  581886  663119  728505  748028  782542\n",
      "  823905  876212  902910  939280  987915 1045969 1078785 1134547 1197866\n",
      " 1237196 1293234 1326364 1375120 1380617 1386943 1396624 1407336 1414313\n",
      " 1420803 1430629 1441467 1448617 1458893 1470138 1477765 1489632 1499063\n",
      " 1509772 1511355 1513873 1518915 1520118 1524974 1531765 1534754 1539821\n",
      " 1541615 1546080 1551272 1558350 1561630 1567567 1570053 1575281 1582003\n",
      " 1585398 1591236 1595040]\n",
      "Number of unique values in each feature 92 [ 7518  4913   130   183   476   361  2951    68 59168 14683 19469 27849\n",
      " 33130 47424 18885  5247  5463  6044  9431 10522  6694   194  1311  1794\n",
      "  4225   854  1569  2486  5008  1178  3395  5644  1827  3805   361  3253\n",
      " 60000 60960 63587 79826 81233 65386 19523 34514 41363 52307 26698 36370\n",
      " 48635 58054 32816 55762 63319 39330 56038 33130 48756  5497  6326  9681\n",
      " 10712  6977  6490  9826 10838  7150 10276 11245  7627 11867  9431 10709\n",
      "  1583  2518  5042  1203  4856  6791  2989  5067  1794  4465  5192  7078\n",
      "  3280  5937  2486  5228  6722  3395  5838  3804]\n"
     ]
    }
   ],
   "source": [
    "#Initial Encoding for all features\n",
    "\n",
    "encoder = preprocessing.OneHotEncoder(dtype=np.uint32)\n",
    "# we want to encode the category IDs encountered both in\n",
    "# the training and the test set, so we fit the encoder on both\n",
    "encoder.fit(data)\n",
    "X = encoder.transform(data[:test_offset,:])\n",
    "X_test = encoder.transform(data[test_offset:,:])\n",
    "print(X.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(\"Total One Hot Features\",encoder.active_features_)\n",
    "print(\"Boundaries of each Feature\",len(encoder.feature_indices_),encoder.feature_indices_)\n",
    "print(\"Number of unique values in each feature\",len(encoder.n_values_),encoder.n_values_)\n",
    "# print(np.unique(data[:,0]))\n",
    "# print(np.unique(data[:,1]))\n",
    "# sb.barplot(x=np.arange(92),y=encoder.n_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.         ...,  0.          0.          0.00328731]\n"
     ]
    }
   ],
   "source": [
    "#Feature Selection - Gradient Boosting (Filtering)\n",
    "dtc = DecisionTreeClassifier(criterion='entropy')\n",
    "dtc.fit(X,y)\n",
    "print(dtc.feature_importances_)\n",
    "features = dtc.feature_importances_\n",
    "\n",
    "#sb.distplot(feat,bins=100)\n",
    "#print(np.argmax(features),np.max(features))\n",
    "# Sum features in the same bin as defined by encoder.n_values_\n",
    "x = 0\n",
    "start = 0\n",
    "prob_sum = []\n",
    "#prob_ref = dict()\n",
    "for i in encoder.n_values_ : \n",
    "    prob = features[start:i].sum()\n",
    "    prob_sum.append(prob)\n",
    "    #prob_ref[header[x]] = prob \n",
    "    start = i + 1\n",
    "    #x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.    0.    0.   ...,  0.    0.    0.06]\n",
      "[59.769999999999996, 0.0, 0.0, 1.4550000000000001, 6.4700000000000006, 0.0, 30.140000000000004, 0.0, 239.92499999999998, 0.0, 32.344999999999999, 0.19500000000000001, 1.095, 0.66000000000000003, 0.0, 0.0, 0.53000000000000003, 4.6400000000000006, 24.219999999999999, 11.039999999999999, 0.0, 0.0, 19.454999999999998, 5.4199999999999999, 16.149999999999999, 0.0, 11.120000000000001, 6.1400000000000006, 16.865000000000002, 0.0, 17.355, 15.790000000000001, 0.0, 14.264999999999999, 0.0, 32.030000000000001, 201.80000000000001, 0.0, 0.29000000000000004, 18.065000000000005, 5.5, 0.0, 0.0, 1.4850000000000001, 0.46000000000000002, 0.38500000000000001, 0.0, 1.54, 0.21500000000000002, 0.97000000000000008, 0.0, 1.6300000000000001, 0.78000000000000003, 0.0, 1.1850000000000001, 0.0, 0.66000000000000003, 0.0, 4.7300000000000004, 26.365000000000002, 9.6550000000000011, 0.0, 0.0, 28.925000000000001, 5.9550000000000001, 0.0, 31.620000000000001, 5.8650000000000002, 0.0, 37.289999999999999, 0.0, 12.254999999999999, 0.0, 6.1450000000000005, 16.859999999999999, 0.0, 25.740000000000002, 10.015000000000001, 0.0, 13.949999999999999, 0.0, 17.205000000000002, 5.5449999999999999, 7.665, 0.0, 17.745000000000001, 0.0, 17.609999999999999, 7.1149999999999993, 0.0, 16.805, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Stability Selection using Randomized Lasso\n",
    "\n",
    "rlasso = linear_model.RandomizedLogisticRegression(C=1)\n",
    "rlasso.fit(X,y)\n",
    "\n",
    "rlasso_score = rlasso.scores_\n",
    "\n",
    "x = 0\n",
    "start = 0\n",
    "prob_sum = []\n",
    "for i in encoder.n_values_ : \n",
    "    prob_sum.append(rlasso_score[start:i].sum())\n",
    "    start = i + 1\n",
    "\n",
    "print(rlasso_score)\n",
    "print(prob_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Feature Selection - Greedy Algorithm (Wrapping)\n",
    "\n",
    "estimator = linear_model.LogisticRegression(C=1)\n",
    "selector = RFE(estimator)\n",
    "selector = selector.fit(X, y)\n",
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 4, 6, 8, 10, 11, 12, 13, 16, 17, 18, 19, 22, 23, 24, 26, 27, 28, 30, 31, 33, 35, 36, 38, 39, 40, 43, 44, 45, 47, 48, 49, 51, 52, 54, 56, 58, 59, 60, 63, 64, 66, 67, 69, 71, 73, 74, 76, 77, 79, 81, 82, 83, 85, 87, 88, 90]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RESOURCE',\n",
       " 'ROLE_ROLLUP_2',\n",
       " 'ROLE_DEPTNAME',\n",
       " 'ROLE_FAMILY_DESC',\n",
       " 'ROLE_CODE',\n",
       " 'RESOURCE&ROLE_ROLLUP_1',\n",
       " 'RESOURCE&ROLE_ROLLUP_2',\n",
       " 'RESOURCE&ROLE_DEPTNAME',\n",
       " 'RESOURCE&ROLE_TITLE',\n",
       " 'MGR_ID&ROLE_ROLLUP_1',\n",
       " 'MGR_ID&ROLE_ROLLUP_2',\n",
       " 'MGR_ID&ROLE_DEPTNAME',\n",
       " 'MGR_ID&ROLE_TITLE',\n",
       " 'ROLE_ROLLUP_1&ROLE_ROLLUP_2',\n",
       " 'ROLE_ROLLUP_1&ROLE_DEPTNAME',\n",
       " 'ROLE_ROLLUP_1&ROLE_TITLE',\n",
       " 'ROLE_ROLLUP_1&ROLE_FAMILY',\n",
       " 'ROLE_ROLLUP_2&ROLE_DEPTNAME',\n",
       " 'ROLE_ROLLUP_2&ROLE_TITLE',\n",
       " 'ROLE_ROLLUP_2&ROLE_FAMILY',\n",
       " 'ROLE_DEPTNAME&ROLE_TITLE',\n",
       " 'ROLE_DEPTNAME&ROLE_FAMILY',\n",
       " 'ROLE_TITLE&ROLE_FAMILY',\n",
       " 'ROLE_FAMILY_DESC&ROLE_FAMILY',\n",
       " 'RESOURCE&MGR_ID&ROLE_ROLLUP_2',\n",
       " 'RESOURCE&MGR_ID&ROLE_DEPTNAME',\n",
       " 'RESOURCE&MGR_ID&ROLE_TITLE',\n",
       " 'RESOURCE&ROLE_ROLLUP_1&ROLE_ROLLUP_2',\n",
       " 'RESOURCE&ROLE_ROLLUP_1&ROLE_DEPTNAME',\n",
       " 'RESOURCE&ROLE_ROLLUP_1&ROLE_TITLE',\n",
       " 'RESOURCE&ROLE_ROLLUP_1&ROLE_FAMILY',\n",
       " 'RESOURCE&ROLE_ROLLUP_2&ROLE_DEPTNAME',\n",
       " 'RESOURCE&ROLE_ROLLUP_2&ROLE_TITLE',\n",
       " 'RESOURCE&ROLE_ROLLUP_2&ROLE_FAMILY',\n",
       " 'RESOURCE&ROLE_DEPTNAME&ROLE_TITLE',\n",
       " 'RESOURCE&ROLE_DEPTNAME&ROLE_FAMILY',\n",
       " 'RESOURCE&ROLE_TITLE&ROLE_FAMILY',\n",
       " 'MGR_ID&ROLE_ROLLUP_1&ROLE_ROLLUP_2',\n",
       " 'MGR_ID&ROLE_ROLLUP_1&ROLE_DEPTNAME',\n",
       " 'MGR_ID&ROLE_ROLLUP_1&ROLE_TITLE',\n",
       " 'MGR_ID&ROLE_ROLLUP_2&ROLE_DEPTNAME',\n",
       " 'MGR_ID&ROLE_ROLLUP_2&ROLE_TITLE',\n",
       " 'MGR_ID&ROLE_ROLLUP_2&ROLE_FAMILY',\n",
       " 'MGR_ID&ROLE_DEPTNAME&ROLE_TITLE',\n",
       " 'MGR_ID&ROLE_DEPTNAME&ROLE_FAMILY',\n",
       " 'MGR_ID&ROLE_TITLE&ROLE_FAMILY',\n",
       " 'ROLE_ROLLUP_1&ROLE_ROLLUP_2&ROLE_DEPTNAME',\n",
       " 'ROLE_ROLLUP_1&ROLE_ROLLUP_2&ROLE_TITLE',\n",
       " 'ROLE_ROLLUP_1&ROLE_ROLLUP_2&ROLE_FAMILY',\n",
       " 'ROLE_ROLLUP_1&ROLE_DEPTNAME&ROLE_TITLE',\n",
       " 'ROLE_ROLLUP_1&ROLE_DEPTNAME&ROLE_FAMILY',\n",
       " 'ROLE_ROLLUP_1&ROLE_TITLE&ROLE_FAMILY',\n",
       " 'ROLE_ROLLUP_1&ROLE_FAMILY_DESC&ROLE_FAMILY',\n",
       " 'ROLE_ROLLUP_2&ROLE_DEPTNAME&ROLE_TITLE',\n",
       " 'ROLE_ROLLUP_2&ROLE_DEPTNAME&ROLE_FAMILY',\n",
       " 'ROLE_ROLLUP_2&ROLE_TITLE&ROLE_FAMILY',\n",
       " 'ROLE_ROLLUP_2&ROLE_FAMILY_DESC&ROLE_FAMILY',\n",
       " 'ROLE_DEPTNAME&ROLE_TITLE&ROLE_FAMILY']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFbCAYAAAD4J9aTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7gQ+azDJdk8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9516690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pick out the most useful features\n",
    "\n",
    "sb.barplot(y=prob_sum,x=np.arange(92))\n",
    "#hsb = sb.hist(prob_sum,xlim=0.1)\n",
    "#Look at bar plot to see what threshold of the features to select\n",
    "ufeatures = []\n",
    "for i,j in enumerate(prob_sum):\n",
    "    if (j>0) : ufeatures.append(i)\n",
    "print(ufeatures)\n",
    "[header[i] for i in ufeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 7, 8, 9, 10, 36, 37, 38, 41, 42, 43, 47, 51, 53, 56, 60, 61, 63, 64, 66, 67, 69, 71, 75, 79, 85, 91]\n"
     ]
    }
   ],
   "source": [
    "# Kaggle Greedy Algorithm result\n",
    "#ufeatures = [0, 8, 9, 10, 19, 34, 36, 37, 38, 41, 42, 43, 47, 53, 55, 60, 61, 63, 64, 67, 69, 71, 75, 81, 82, 85]\n",
    "ufeatures = [0, 1, 7, 8, 9, 10, 36, 37, 38, 41, 42, 43, 47, 51, 53, 56, 60, 61, 63, 64, 66, 67, 69, 71, 75, 79, 85, 91]\n",
    "print(ufeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32769, 688468)\n",
      "(58921, 688468)\n"
     ]
    }
   ],
   "source": [
    "#OneHotEncoder for the best features only\n",
    "\n",
    "encode_bfeat = preprocessing.OneHotEncoder(dtype=np.uint32)\n",
    "# we want to encode the category IDs encountered both in\n",
    "# the training and the test set, so we fit the encoder on both\n",
    "encode_bfeat.fit(data[:,ufeatures])\n",
    "X = encode_bfeat.transform(data[:test_offset,ufeatures])\n",
    "X_test = encode_bfeat.transform(data[test_offset:,ufeatures])\n",
    "print(X.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC (fold 1/10): 0.815973\n",
      "AUC (fold 2/10): 0.805022\n",
      "AUC (fold 3/10): 0.808922\n",
      "AUC (fold 4/10): 0.805295\n",
      "AUC (fold 5/10): 0.803692\n",
      "AUC (fold 6/10): 0.810595\n",
      "AUC (fold 7/10): 0.795956\n",
      "AUC (fold 8/10): 0.804126\n",
      "AUC (fold 9/10): 0.809816\n",
      "AUC (fold 10/10): 0.796265\n",
      "Mean AUC: 0.805566\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "mean_auc = 0.0\n",
    "\n",
    "n = 10  # repeat the CV procedure 10 times to get more precise results\n",
    "model = ensemble.RandomForestClassifier(criterion='entropy')\n",
    "#model = linear_model.LogisticRegression(C=1,penalty='l2',class_weight='balanced')\n",
    "#model = BernoulliNB(alpha=0.005)\n",
    "#model = ensemble.ExtraTreesClassifier(criterion='entropy',n_jobs=-1,verbose=1)\n",
    "for i in range(n):\n",
    "    # for each iteration, randomly hold out 20% of the data as CV set\n",
    "    X_train, X_cv, y_train, y_cv = cross_validation.train_test_split(X, y, test_size=.20, random_state=i*SEED)\n",
    "\n",
    "    # if you want to perform feature selection / hyperparameter\n",
    "    # optimization, this is where you want to do it\n",
    "\n",
    "    # train model and make predictions\n",
    "    model.fit(X_train, y_train) \n",
    "    preds = model.predict_proba(X_cv)[:, 1]\n",
    "\n",
    "    # compute AUC metric for this CV fold\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_cv, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print(\"AUC (fold %d/%d): %f\" % (i + 1, n, roc_auc))\n",
    "    mean_auc += roc_auc\n",
    "\n",
    "print(\"Mean AUC: %f\" % (mean_auc/n))\n",
    "\n",
    "# === Predictions === #\n",
    "# When making predictions, retrain the model on the whole training set\n",
    "model.fit(X, y)\n",
    "preds = model.predict_proba(X_test)[:, 1]\n",
    "save_results(preds, \"submit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Numpy Operations\n",
    "# print(np.fromiter(t_data[0],np.int32))\n",
    "# print(np.fromiter(t_data[1],np.int32))\n",
    "# print(np.fromiter(t_data[2],np.int32))\n",
    "# print(np.fromiter(t_data[3],np.int32))\n",
    "# print(np.fromiter(t_data[4],np.int32))\n",
    "# print(np.fromiter(t_data[5],np.int32))\n",
    "\n",
    "# Convert to numpy array - Use np.array(list)\n",
    "# for i in nparray - iterate through rows\n",
    "# for i in nparray.T - iterate through columns\n",
    "# Initialize np.zeros(5)\n",
    "\n",
    "# To view generator operators (Use list,tuples)\n",
    "# for i,j in enumerate(t_data):\n",
    "#     #lst_array[i] = np.array(list(j))\n",
    "#     lst_array[i] = np.fromiter(j,np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC = Logistic Regression returns the probability that a certain input features would be in a certain class\n",
    "ROC curve visualizaes all possible thresholds\n",
    "Misclassification rate is error rate for a single threshold\n",
    "\n",
    "\n",
    "Attempt with original features only : CV : ... , Public : 0.88515, Private : 0.88205\n",
    "\n",
    "Attempt with original features + combination of 3 : CV : 0.886375 , Public : 0.90141, Private 0.89582 \n",
    "ExtraTreeClassifier = submit_etc.csv\n",
    "\n",
    "\n",
    "Attempt with original features + combination of 3 : CV : 0.886375 , Public : 0.90141, Private 0.89582 \n",
    "Logistic C=1, class_weight='balanced',penalty='l2' = submit_c3.csv\n",
    "\n",
    "Attempt with DTC selected features : CV :  0.886555 (threshold >0) , Public : , Private \n",
    "j>0.001 or 0 \n",
    "Logistic\n",
    "\n",
    "Attempt with Random Lasso  : CV : 0.886439   , Public : , Private \n",
    "j>0\n",
    "Logistic C=1, class_weight='balanced',penalty='l2' = submit_rl.csv\n",
    "\n",
    "Cheat Sheet from Kaggle, CV : 0.895952\n",
    "Logistic C=1, class_weight='balanced',penalty='l2' = submit_kc.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing Random Forest Tree\n",
    "rf_head = [0,1,22,4,6,35]\n",
    "#rf_head = [0,1,22]\n",
    "rf_data = pd.DataFrame(data[:1000,:])\n",
    "rf_data = rf_data[rf_head]\n",
    "rf_data.columns = [header[i] for i in rf_head]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/c/caterpillar-tube-pricing/forums/t/15748/strategies-to-encode-categorical-variables-with-many-categories\n",
    "#Count/Freq\n",
    "for col in rf_data.columns:\n",
    "    rf_data['cnt'+col] = 0\n",
    "    groups = rf_data.groupby([col])\n",
    "    # gid is the grouped col id, group is the actionable pandas data structure\n",
    "    for gid, group in groups:\n",
    "        #Count total number of rows with the same (MGR_ID,RESOURCE_ID etc) in the entire dataset\n",
    "        count = group[col].count()\n",
    "        #For all rows with the same \"MGR_ID\"/\"RESOURCE_ID\" , put the same count calculated in the previous step\n",
    "        rf_data['cnt'+col].ix[group.index] = count \n",
    "    #rf_data['cnt'+col] = rf_data['cnt'+col].apply(np.log) # could check if this is neccesary, I think probably not\n",
    "    \n",
    "# Percent of dept that is this resource\n",
    "for col in rf_data.columns[1:6]:\n",
    "    rf_data['Duse'+col] = 0.0\n",
    "    groups = rf_data.groupby([col])\n",
    "    for name, group in groups:\n",
    "        grps = group.groupby(['RESOURCE'])\n",
    "        for rsrc, grp in grps:\n",
    "            rf_data['Duse'+col].ix[grp.index] = float(len(grp.index)) / float(len(group.index) )\n",
    "\n",
    "# Number of resources that a manager manages\n",
    "# for col in rf_data.columns[0:1]:\n",
    "#     rf_data['Mdeps'+col] = 0\n",
    "#     groups = rf_data.groupby(['MGR_ID'])\n",
    "#     for name, group in groups:\n",
    "#         rf_data['Mdeps'+col].ix[group.index] = len(group[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESOURCE\n"
     ]
    }
   ],
   "source": [
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
