{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import itertools\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging, gensim\n",
    "from gensim import corpora, models, similarities,matutils\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "import nltk\n",
    "# nltk.download()\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures, TrigramAssocMeasures\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import sklearn.datasets\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',level=logging.INFO)\n",
    "logging.root.level = logging.INFO  # ipython sometimes messes up the logging setup; restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_message(message):\n",
    "    \"\"\"\n",
    "    Preprocess a single 20newsgroups message, returning the result as\n",
    "    a unicode string.\n",
    "    \n",
    "    \"\"\"\n",
    "    extracted = 1\n",
    "    message = gensim.utils.to_unicode(message, 'latin1').strip()\n",
    "    logging.info(\"extracting 20newsgroups file #%i: %s\" % (extracted,message[:10]))\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Load Data\n",
    "# corpus = corpora.MmCorpus('20newsgroup.mm')\n",
    "# dictionary = corpora.Dictionary.load('20newsgroup.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = sklearn.datasets.fetch_20newsgroups(subset='train',remove=('headers','footers','quotes'))\n",
    "# train = sklearn.datasets.fetch_20newsgroups(subset='train')\n",
    "test = sklearn.datasets.fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:extracting 20newsgroups file #1: A fair num\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"A fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train.target_names\n",
    "#train.filenames\n",
    "#train.target[:10]\n",
    "documents = train.data\n",
    "process_message(documents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nltk.download()\n",
    "# test = word_tokenize(documents[1])\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "s = nltk.stem.SnowballStemmer('english')\n",
    "stop = stopwords.words('english')\n",
    "texts = []\n",
    "\n",
    "# [texts.append(set([s.stem(word) for sent in sent_tokenize(doc) for word in tokenizer.tokenize(sent) if word.lower() not in stop])) for doc in documents]\n",
    "\n",
    "# stopwords are in lower case ... \n",
    "# for doc in documents:\n",
    "#     for sent in sent_tokenize(doc):\n",
    "#         texts.append([s.stem(word) for word in tokenizer.tokenize(sent) if word.lower() not in stop])\n",
    "\n",
    "for doc in documents:\n",
    "    texts.append([s.stem(word) for word in tokenizer.tokenize(doc) if word.lower() not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dictionary = corpora.Dictionary(line.lower().split() for line in open('mycorpus.txt'))\n",
    "# Maps a word to a ID\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save('20newsgroup.dict') # store the dictionary, for future reference\n",
    "# print(dictionary)\n",
    "# print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newsgrp20 = [dictionary.doc2bow(text) for text in texts]\n",
    "corpora.MmCorpus.serialize('20newsgroup.mm', newsgrp20) # store to disk, for later use\n",
    "# newsgrp20 = corpora.MmCorpus('20newsgroup.mm')\n",
    "# Word ID , Frequency for each document\n",
    "# print(newsgrp20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tfidf = models.TfidfModel(newsgrp20) # Initialize Tfidf\n",
    "# corpus_tfidf = tfidf[newsgrp20] # Transform Test Corpus\n",
    "\n",
    "# lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2) # initialize an LSI transformation\n",
    "# corpus_lsi = lsi[corpus_tfidf] # create a double wrapper over the original corpus: corpus->tfidf->fold-in-lsi\n",
    "\n",
    "lda_model = models.ldamodel.LdaModel(newsgrp20, id2word=dictionary, num_topics=100,passes=10)\n",
    "# model = hdpmodel.HdpModel(bow_corpus, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  '0.010*write + 0.009*edu + 0.008*com + 0.007*one + 0.007*would + 0.007*peopl + 0.006*articl + 0.006*like + 0.006*get + 0.005*chip'),\n",
       " (67,\n",
       "  '0.017*edu + 0.009*like + 0.009*get + 0.008*write + 0.008*myer + 0.007*appl + 0.007*duo + 0.006*articl + 0.006*would + 0.006*com'),\n",
       " (30,\n",
       "  '0.572*ax + 0.042*max + 0.024*q + 0.021*3 + 0.014*g9v + 0.012*p + 0.011*7 + 0.009*r + 0.008*g + 0.008*n'),\n",
       " (39,\n",
       "  '0.022*1 + 0.018*2 + 0.015*use + 0.013*3 + 0.011*printer + 0.008*print + 0.007*4 + 0.007*5 + 0.007*format + 0.006*imag'),\n",
       " (15,\n",
       "  '0.013*armenian + 0.009*one + 0.008*peopl + 0.006*said + 0.005*turkish + 0.005*know + 0.005*say + 0.005*turk + 0.005*go + 0.005*turkey'),\n",
       " (82,\n",
       "  '0.010*ax + 0.007*3 + 0.007*q + 0.006*reinstal + 0.006*za + 0.005*x + 0.005*8051 + 0.004*g + 0.004*3x + 0.004*1'),\n",
       " (41,\n",
       "  '0.013*com + 0.011*ivf + 0.010*idl + 0.009*sgi + 0.009*trunk + 0.007*silicon + 0.007*rash + 0.007*386bsd + 0.006*mislead + 0.006*svr4'),\n",
       " (4,\n",
       "  '0.023*ax + 0.019*einstein + 0.008*albert + 0.007*parad + 0.006*solv + 0.006*3 + 0.005*___________________the + 0.005*champion_________________ + 0.005*darkman + 0.005*1946'),\n",
       " (73,\n",
       "  '0.026*god + 0.015*church + 0.010*bibl + 0.009*one + 0.009*christian + 0.008*jesus + 0.008*write + 0.007*edu + 0.006*cathol + 0.006*would'),\n",
       " (59,\n",
       "  '0.207*_ + 0.040*___ + 0.039*__ + 0.011*____ + 0.009*edu + 0.009*buffalo + 0.005*ranck + 0.005*lost + 0.005*_____ + 0.005*migrain')]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topics = lda_model[newsgrp20]\n",
    "lda_model.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 18, 29, 56, 61, 63, 95]\n",
      "[0.071825355564549401, 0.041109278803422564, 0.084390555880771073, 0.092887532429586347, 0.20686000864636928, 0.028660225666514026, 0.45671987319746593]\n",
      "['mail', 'spec', 'small', 'washington', 'next', 'number', 'hour']\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_num = 0\n",
    "topic_index = [int(i[0]) for i in topics[doc_num]]\n",
    "print(topic_index)\n",
    "print([(i[1]) for i in topics[doc_num]])\n",
    "print([dictionary.id2token[x] for x in topic_index])\n",
    "print(documents[doc_num])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 8.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.]),\n",
       " array([ 1. ,  1.1,  1.2,  1.3,  1.4,  1.5,  1.6,  1.7,  1.8,  1.9,  2. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAECCAYAAADn84z1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyoBLUlEGXJKKMuCSVJQBl6Si/g8IV7qumB+ETQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a2d4bf4d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_topics = [len(lda_model[doc]) for doc in corpus_tfidf]\n",
    "plt.hist(num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x  (2, 2)\n"
     ]
    }
   ],
   "source": [
    "# x = np.array([[1,2],[2,4]])\n",
    "# print(\"x \",x.shape) - 2,2\n",
    "# y = np.array([[1,2],[2,4]])\n",
    "# print(\"x \",y.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# s = nltk.stem.SnowballStemmer('english')\n",
    "# class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "#     def build_analyzer(self):\n",
    "#         #StemmedCountVectorizer will return CountVectorizer build_analyzer code\n",
    "#         analyzer = super(TfidfVectorizer,self).build_analyzer()\n",
    "#         return lambda doc: (s.stem(w) for w in analyzer(doc))\n",
    "\n",
    "# # default min_df = 1, max_df = 1.0\n",
    "# # In other words, tf-idf weight in document that is\n",
    "# # highest when the terms occurs many times within a small number of documents (thus lending high discriminating power to those documents);\n",
    "# # lower when the term occurs fewer times in a document, or occurs in many documents (thus offering a less pronounced relevance signal);\n",
    "# # lowest when the term occurs in virtually all documents.\n",
    "# vectorizer = StemmedTfidfVectorizer(min_df=1,stop_words='english',decode_error='ignore')\n",
    "\n",
    "# vectorized = vectorizer.fit_transform(documents)\n",
    "# features = np.array(vectorizer.get_feature_names())\n",
    "# # type(features)\n",
    "# texts = [list(features[list((vectorized>0)[i].nonzero()[1])]) for i,doc in enumerate(documents)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
