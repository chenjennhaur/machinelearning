{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Role Title and Role Code are similar based on pandas\n",
    "*Instead of using hashing, can consider cantor(m,n) = 1/2 * (m+n)(m+n+1)+m. Beware of hash collision\n",
    "*PCA / SVD are more suited for continuous values. For discrete variables, consider using MCA\n",
    "1. Feature Extraction - Using Genetic Algorithm / Greedy Algorithm [sklearn.feature_selection.RFE, RFECV , Gradient Boosting\n",
    "2. Try using Stacked Classifier \n",
    "  * np.mean\n",
    "  * weighted mean\n",
    "  * jaccard score\n",
    "  * pass the results from each classifer into another RF / Linear Regression\n",
    "3. Data Exploratory - Find if train has more classes compared to test ? \n",
    "4. Try to run on Spark\n",
    "5. Stratified K Fold Cross Validation\n",
    "6. Use GridSearchCV to optimize Logistic Classifier\n",
    "7. Consider having equal +ve and -ve examples in each train dataset\n",
    "\n",
    "8. Count Analysis (Use Log Odd Ratio) + Two Class AdaBoosted Decision Tree\n",
    "9. Compare between average and voting for Ensemble. How to combine Logistic (X,y) and RFC (X1,y1)\n",
    "10. Make a graph of count / np.log rf_data[] against y [scatterplot]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ACTION is 1 if the resource was approved, 0 if the resource was not\n",
    "* RESOURCE - An ID for each resource\n",
    "* MGR_ID- The EMPLOYEE ID of the manager of the current EMPLOYEE ID record; an employee may have only one manager at a time\n",
    "* ROLE_ROLLUP_1 - Company role grouping category id 1 (e.g. US Engineering)\n",
    "* ROLE_ROLLUP_2 - Company role grouping category id 2 (e.g. US Retail)\n",
    "* ROLE_DEPTNAME - Company role department description (e.g. Retail)\n",
    "* ROLE_TITLE - Company role business title description (e.g. Senior Engineering Retail Manager) - Same as Role Code\n",
    "* ROLE_FAMILY_DESC - Company role family extended description (e.g. Retail Manager, Software Engineering)\n",
    "* ROLE_FAMILY - Company role family description (e.g. Retail Manager)\n",
    "* ROLE_CODE - Company role code; this code is unique to each role (e.g. Manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#inside a ipython/nb session\n",
    "# Original Data in Pandas Dataframe : data\n",
    "# Sparse Array for Training Data : X\n",
    "# Sparse Array for Test Data : X_test\n",
    "# Label for X only : y\n",
    "# Offset : test_offset\n",
    "# rf_data : Data Set for Random Forest Tree\n",
    "\n",
    "\n",
    "#inside a ipython/nb session\n",
    "# %store encoder\n",
    "# Original Data in Pandas Dataframe\n",
    "# %store data\n",
    "# Sparse Array for Training Data\n",
    "# %store X\n",
    "# Sparse Array for Test Data\n",
    "# %store X_test\n",
    "# Label for X only\n",
    "# %store y\n",
    "# %store features\n",
    "# %store header\n",
    "# Offset \n",
    "# %store test_offset\n",
    "# Data Set for Random Forest Tree\n",
    "# %store rf_data\n",
    "\n",
    "%store -r encoder\n",
    "%store -r data\n",
    "%store -r X\n",
    "%store -r X_test\n",
    "%store -r y\n",
    "%store -r features\n",
    "%store -r header\n",
    "%store -r test_offset\n",
    "%store -r rf_data\n",
    "\n",
    "\n",
    "# fileObject = open(\"amazon.pickle\",'wb') \n",
    "# pickle.dump(encoder,fileObject)   \n",
    "# pickle.dump(data,fileObject)   \n",
    "# pickle.dump(X,fileObject)   \n",
    "# pickle.dump(X_test,fileObject)   \n",
    "# pickle.dump(y,fileObject)   \n",
    "# pickle.dump(features,fileObject)   \n",
    "# pickle.dump(header,fileObject)   \n",
    "# pickle.dump(test_offset,fileObject)   \n",
    "# pickle.dump(rf_data,fileObject)   \n",
    "# fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pivottablejs import pivot_ui\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt  \n",
    "from ipywidgets import widgets\n",
    "import numpy as np\n",
    "from sklearn import (metrics, cross_validation, linear_model, preprocessing)\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import (GradientBoostingClassifier,RandomForestClassifier)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import ensemble\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn import grid_search\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sb.set(style=\"ticks\", color_codes=True)\n",
    "df = pd.read_csv('train.csv')\n",
    "dft = pd.read_csv('test.csv')\n",
    "#g = sb.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#len(df['RESOURCE'].value_counts())\n",
    "#df['RESOURCE'].plot.hist(bins=7518)\n",
    "#df.head()\n",
    "#dfc = df.iloc[:,1:10] \n",
    "dfc = df.iloc[:,:]\n",
    "for col in df.columns:\n",
    "  dfc[col] = df[col].astype('category')\n",
    "dfc.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_one_hot = 0\n",
    "for col in dfc.columns[1:]:\n",
    "  total_one_hot += len(pd.unique(dfc[col]))\n",
    "print(\"Total Features :\",total_one_hot)\n",
    "\n",
    "dfc['ACTION'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Observation Only\n",
    "#test = pd.pivot_table(dfc,index=['ROLE_TITLE','ROLE_CODE'],aggfunc='count',dropna=True)\n",
    "#dfc.pivot_table(index='ROLE_TITLE',aggfunc=lambda x:len(x.unique()))\n",
    "mult = {}\n",
    "for c in df.columns:\n",
    "    temp = df.pivot_table(index=c,aggfunc=lambda x:len(x.unique()),fill_value=0).apply(np.max)\n",
    "    mult[c] = temp\n",
    "\n",
    "multpd = pd.DataFrame(mult)\n",
    "\n",
    "multpd[multpd.columns[1:]]\n",
    "#Role Code to Role Title => 1:1\n",
    "#Role Family to Role Code => 1 : M\n",
    "#Role Family to Role Title => 1 : M\n",
    "#Therefore Role Code = Role Title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Action, Resource, Role_Code, Role_DeptName, Role_Family, Role_Family_Desc, Role_Roll_1, Role_Roll_2, Role_Title\n",
    "mgr = df.pivot_table(index='MGR_ID',aggfunc= lambda x:len(x.unique()),fill_value=0)\n",
    "mgr.hist(bins=20,figsize=(10,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data Frame Analysis (Obeservation Only)\n",
    "# # pd.set_option('display.max_rows',500)\n",
    "# mgr_id_high = mgr.sort_values(by=['RESOURCE'],ascending=False)['RESOURCE'] > 30\n",
    "# print(\"MGR where resources less:\", len(mgr_id_high.index.values[~mgr_id_high.values]))\n",
    "# print(\"MGR where resources more:\", len(mgr_id_high.index.values[mgr_id_high.values]))\n",
    "# print(\"Total:\",len(k.index.values))\n",
    "# #df[df['MGR_ID'].isin(k)]\n",
    "\n",
    "# #df[(df['ACTION']==0)][['ACTION']].count()\n",
    "# mgr_total = df[(df['MGR_ID'].isin(mgr_id_high.index.values[k.values]))][['ACTION']].count()\n",
    "# mgr_action_1 = df[(df['MGR_ID'].isin(mgr_id_high.index.values[k.values])) & (df['ACTION']==1)][['ACTION']].count()\n",
    "# mgr_action_0 = df[(df['MGR_ID'].isin(mgr_id_high.index.values[k.values])) & (df['ACTION']==0)][['ACTION']].count()\n",
    "# print(\"Percentage MGR : \",mgr_action_0/mgr_total)\n",
    "# #df[['ACTION','RESOURCE','MGR_ID']]\n",
    "# # k.pivot_table(index='RESOURCE',aggfunc='count')\n",
    "\n",
    "# mgr_total_o = df[(~df['MGR_ID'].isin(mgr_id_high.index.values[k.values]))][['ACTION']].count()\n",
    "# mgr_action_1_o = df[(~df['MGR_ID'].isin(mgr_id_high.index.values[k.values])) & (df['ACTION']==1)][['ACTION']].count()\n",
    "# mgr_action_0_o = df[(~df['MGR_ID'].isin(mgr_id_high.index.values[k.values])) & (df['ACTION']==0)][['ACTION']].count()\n",
    "# print(\"Percentage MGR : \",mgr_action_0_o/mgr_total_o)\n",
    "# print(\"Mgr_less\", mgr_total_o,\"   \",mgr_action_1_o,\"    \",mgr_action_0_o)\n",
    "# print(\"Mgr_more\", mgr_total,\"   \",mgr_action_1,\"    \",mgr_action_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Action, Resource, Role_Code, Role_DeptName, Role_Family, Role_Family_Desc, Role_Roll_1, Role_Roll_2, Role_Title\n",
    "rollup1 = df.pivot_table(index='ROLE_ROLLUP_1',aggfunc= lambda x:len(x.unique()),fill_value=0)\n",
    "rollup1['ROLE_ROLLUP_2'].hist()\n",
    "rollup1['ROLE_ROLLUP_2'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rollup2 = df.pivot_table(index='ROLE_ROLLUP_2',aggfunc= lambda x:len(x.unique()),fill_value=0)\n",
    "rollup2['ROLE_ROLLUP_1'].hist()\n",
    "rollup2['ROLE_ROLLUP_1'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abc = pd.concat([df['ACTION'],rf_data[:test_offset][rf_data.columns.values[6:12]]], axis=1)\n",
    "sb.regplot(abc['cntROLE_ROLLUP_1&ROLE_ROLLUP_2'],abc['ACTION'],scatter=True)\n",
    "# abc[['ACTION','cntMGR_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_results(predictions, filename):\n",
    "    \"\"\"Given a vector of predictions, save results in CSV format.\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"id,ACTION\\n\")\n",
    "        for i, pred in enumerate(predictions):\n",
    "            f.write(\"%d,%f\\n\" % (i + 1, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cantor(pairs):\n",
    "    result2 = 0.5 * (pairs[0] + pairs[1]) * (pairs[0] + pairs[1] +1) + pairs[1]\n",
    "    if(len(pairs) == 2): \n",
    "        return result2\n",
    "    if(len(pairs) == 3 ):\n",
    "        result3 = 0.5 * (result2 + pairs[2]) * (result2 + pairs[2] +1) + pairs[2]\n",
    "        return result3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert from dataframe to np.array\n",
    "y = np.ravel(df.iloc[:,:1])\n",
    "X = np.array(df.iloc[:,1:9])\n",
    "X_test = np.array(dft.iloc[:,1:9])\n",
    "header = list(df.columns[1:])\n",
    "\n",
    "data = np.vstack((X,X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# yc = combinations(range(n),2)\n",
    "# to view all the combinations\n",
    "# list(yc) \n",
    "\n",
    "#train data[:32769,:]\n",
    "#test data[32769:,:]\n",
    "#tuple is used here so that the result is hashable\n",
    "\n",
    "test_offset = 32769\n",
    "# Get Combinations of 2 features \n",
    "for indices in combinations(range(8),2):\n",
    "    #data = np.column_stack((data,list(ctypes.c_size_t(hash(tuple(v))).value for v in data[:,indices]))) \n",
    "    #data = np.column_stack((data,list(np.uint64(hash(tuple(v))) for v in data[:,indices]))) \n",
    "    #data = np.column_stack((data,list(hash(tuple(v)) for v in data[:,indices]))) \n",
    "    data = np.column_stack((data,list(cantor(tuple(v)) for v in data[:,indices]))) \n",
    "    a,b = indices\n",
    "    header.append(header[a] +\"&\"+ header[b])\n",
    "print('2 Combinations')\n",
    "print(data.shape)\n",
    "print(np.any(data < 0))\n",
    "print(np.ndarray.min(data))\n",
    "print(np.ndarray.max(data))\n",
    "    \n",
    "# Get Combinations of 3 features \n",
    "for indices in combinations(range(8),3):\n",
    "    data = np.column_stack((data,list(cantor(tuple(v)) for v in data[:,indices]))) \n",
    "    a,b,c = indices\n",
    "    header.append(header[a] +\"&\"+ header[b]+ \"&\" + header[c])\n",
    "\n",
    "    \n",
    "#Check loaded correctly with non-zero elements    \n",
    "print('3 Combinations')\n",
    "print(data.shape)\n",
    "print(np.any(data < 0))\n",
    "print(np.ndarray.min(data))\n",
    "print(np.ndarray.max(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Simplify the encoding. Probably not essential. Could possibly improve performance\n",
    "# Vertical Stacking is required so that all the features are captured. There might be some features in test set not in train set\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "data_e = []\n",
    "# To perform column wise operations, use Transpose function\n",
    "for i in data.T:\n",
    "    le.fit(i)\n",
    "    data_e.append(le.transform(i))\n",
    "\n",
    "data = np.asarray(data_e).T\n",
    "\n",
    "print(np.any(data < 0))\n",
    "print(np.ndarray.min(data))\n",
    "print(np.ndarray.max(data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #Code to help Visualize what the algorithm is doing \n",
    "# t_data = []\n",
    "# test_data = np.array([[1,2,3,4],[1,2,2,0],[1,2,3,4],[1,4,5,6],[2,3,4,5]])\n",
    "# print(test_data.shape)\n",
    "\n",
    "# #if the combination of categories are the same, they will be hashed to the same value. Eg 1 row with (0,1,0) will have same \n",
    "# #hash value of another row with (0,1,0)\n",
    "# for indices in combinations(range(4),2):\n",
    "#     t_data.append(hash(tuple(v)) for v in test_data[:,indices])\n",
    "#     #print(v for v in test_data[:,indices])\n",
    "#     print(indices)\n",
    "    \n",
    "# #Comparison 1 - Combinations are (0,1),(0,2),(0,3),(1,2),(1,3),(2,3)\n",
    "# # for v in test_data[:,(0,1)]:\n",
    "# #   print(hash(tuple(v)))\n",
    "\n",
    "# #Comparison 2 - t_data[0] corresponds to (0,1)\n",
    "# #tuple(t_data[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Initial Encoding for all features\n",
    "\n",
    "encoder = preprocessing.OneHotEncoder(dtype=np.uint32)\n",
    "# we want to encode the category IDs encountered both in\n",
    "# the training and the test set, so we fit the encoder on both\n",
    "encoder.fit(data)\n",
    "X = encoder.transform(data[:test_offset,:])\n",
    "X_test = encoder.transform(data[test_offset:,:])\n",
    "print(X.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(\"Total One Hot Features\",encoder.active_features_)\n",
    "print(\"Boundaries of each Feature\",len(encoder.feature_indices_),encoder.feature_indices_)\n",
    "print(\"Number of unique values in each feature\",len(encoder.n_values_),encoder.n_values_)\n",
    "# print(np.unique(data[:,0]))\n",
    "# print(np.unique(data[:,1]))\n",
    "# sb.barplot(x=np.arange(92),y=encoder.n_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Feature Selection - Gradient Boosting (Filtering)\n",
    "dtc = DecisionTreeClassifier(criterion='entropy')\n",
    "dtc.fit(X,y)\n",
    "print(dtc.feature_importances_)\n",
    "features = dtc.feature_importances_\n",
    "\n",
    "#sb.distplot(feat,bins=100)\n",
    "#print(np.argmax(features),np.max(features))\n",
    "# Sum features in the same bin as defined by encoder.n_values_\n",
    "x = 0\n",
    "start = 0\n",
    "prob_sum = []\n",
    "#prob_ref = dict()\n",
    "for i in encoder.n_values_ : \n",
    "    prob = features[start:i].sum()\n",
    "    prob_sum.append(prob)\n",
    "    #prob_ref[header[x]] = prob \n",
    "    start = i + 1\n",
    "    #x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Stability Selection using Randomized Lasso\n",
    "\n",
    "rlasso = linear_model.RandomizedLogisticRegression(C=1)\n",
    "rlasso.fit(X,y)\n",
    "\n",
    "rlasso_score = rlasso.scores_\n",
    "\n",
    "x = 0\n",
    "start = 0\n",
    "prob_sum = []\n",
    "for i in encoder.n_values_ : \n",
    "    prob_sum.append(rlasso_score[start:i].sum())\n",
    "    start = i + 1\n",
    "\n",
    "print(rlasso_score)\n",
    "print(prob_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Feature Selection - Greedy Algorithm (Wrapping)\n",
    "\n",
    "estimator = linear_model.LogisticRegression(C=1)\n",
    "selector = RFE(estimator)\n",
    "selector = selector.fit(X, y)\n",
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pick out the most useful features\n",
    "\n",
    "# sb.barplot(y=prob_sum,x=np.arange(92))\n",
    "#hsb = sb.hist(prob_sum,xlim=0.1)\n",
    "#Look at bar plot to see what threshold of the features to select\n",
    "# ufeatures = []\n",
    "# for i,j in enumerate(prob_sum):\n",
    "#     if (j>0) : ufeatures.append(i)\n",
    "# print(ufeatures)\n",
    "[header[i] for i in ufeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Kaggle Greedy Algorithm result\n",
    "#ufeatures = [0, 8, 9, 10, 19, 34, 36, 37, 38, 41, 42, 43, 47, 53, 55, 60, 61, 63, 64, 67, 69, 71, 75, 81, 82, 85]\n",
    "ufeatures = [0, 1, 7, 8, 9, 10, 36, 37, 38, 41, 42, 43, 47, 51, 53, 56, 60, 61, 63, 64, 66, 67, 69, 71, 75, 79, 85, 91]\n",
    "print(ufeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#OneHotEncoder for the best features only\n",
    "\n",
    "encode_bfeat = preprocessing.OneHotEncoder(dtype=np.uint32)\n",
    "# we want to encode the category IDs encountered both in\n",
    "# the training and the test set, so we fit the encoder on both\n",
    "encode_bfeat.fit(data[:,ufeatures])\n",
    "X = encode_bfeat.transform(data[:test_offset,ufeatures])\n",
    "X_test = encode_bfeat.transform(data[test_offset:,ufeatures])\n",
    "print(X.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing Random Forest Tree\n",
    "rf_head = [0,1,22,4,6,35]\n",
    "rf_data = pd.DataFrame(data)\n",
    "rf_data = rf_data[rf_head]\n",
    "rf_data.columns = [header[i] for i in rf_head]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/c/caterpillar-tube-pricing/forums/t/15748/strategies-to-encode-categorical-variables-with-many-categories\n",
    "# One Time Run Completed\n",
    "#Count/Freq\n",
    "# for col in rf_data.columns:\n",
    "#     rf_data['cnt'+col] = 0\n",
    "#     groups = rf_data.groupby([col])\n",
    "#     # gid is the grouped col id, group is the actionable pandas data structure\n",
    "#     for gid, group in groups:\n",
    "#         #Count total number of rows with the same (MGR_ID,RESOURCE_ID etc) in the entire dataset\n",
    "#         count = group[col].count()\n",
    "#         #For all rows with the same \"MGR_ID\"/\"RESOURCE_ID\" , put the same count calculated in the previous step\n",
    "#         rf_data['cnt'+col].ix[group.index] = count \n",
    "#     #rf_data['cnt'+col] = rf_data['cnt'+col].apply(np.log) # could check if this is neccesary, I think probably not\n",
    "    \n",
    "# # Percent of dept that is this resource\n",
    "# for col in rf_data.columns[1:6]:\n",
    "#     rf_data['Duse'+col] = 0.0\n",
    "#     groups = rf_data.groupby([col])\n",
    "#     for name, group in groups:\n",
    "#         grps = group.groupby(['RESOURCE'])\n",
    "#         for rsrc, grp in grps:\n",
    "#             rf_data['Duse'+col].ix[grp.index] = float(len(grp.index)) / float(len(group.index) )\n",
    "\n",
    "# #Number of resources that a manager manages\n",
    "# for col in rf_data.columns[0:1]:\n",
    "#     rf_data['Mdeps'+col] = 0\n",
    "#     groups = rf_data.groupby(['MGR_ID'])\n",
    "#     for name, group in groups:\n",
    "#         rf_data['Mdeps'+col].ix[group.index] = len(group[col].unique())\n",
    "\n",
    "X = rf_data.values[:test_offset,6:18]\n",
    "X_test = rf_data.values[test_offset:,6:18]\n",
    "\n",
    "# X = rf_data.values[:test_offset,:]\n",
    "# X_test = rf_data.values[test_offset:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "SEED = 42\n",
    "mean_auc = 0.0\n",
    "\n",
    "n = 10  # repeat the CV procedure 10 times to get more precise results\n",
    "model = linear_model.LogisticRegression(C=1,penalty='l2',class_weight='balanced')\n",
    "#model = BernoulliNB(alpha=0.005)\n",
    "#model = ensemble.ExtraTreesClassifier(criterion='entropy',n_jobs=-1,verbose=1)\n",
    "for i in range(n):\n",
    "    # for each iteration, randomly hold out 20% of the data as CV set\n",
    "    X_train, X_cv, y_train, y_cv = cross_validation.train_test_split(X, y, test_size=.20, random_state=i*SEED)\n",
    "\n",
    "    # if you want to perform feature selection / hyperparameter\n",
    "    # optimization, this is where you want to do it\n",
    "\n",
    "    # train model and make predictions\n",
    "    model.fit(X_train, y_train) \n",
    "    preds = model.predict_proba(X_cv)[:, 1]\n",
    "\n",
    "    # compute AUC metric for this CV fold\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_cv, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print(\"AUC (fold %d/%d): %f\" % (i + 1, n, roc_auc))\n",
    "    mean_auc += roc_auc\n",
    "    # To print curve\n",
    "#     plt.plot(fpr,tpr)\n",
    "#     plt.show() \n",
    "\n",
    "print(\"Mean AUC: %f\" % (mean_auc/n))\n",
    "\n",
    "# === Predictions === #\n",
    "# When making predictions, retrain the model on the whole training set\n",
    "model.fit(X, y)\n",
    "preds = model.predict_proba(X_test)[:, 1]\n",
    "save_results(preds, \"submit_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Numpy Operations\n",
    "# print(np.fromiter(t_data[0],np.int32))\n",
    "# print(np.fromiter(t_data[1],np.int32))\n",
    "# print(np.fromiter(t_data[2],np.int32))\n",
    "# print(np.fromiter(t_data[3],np.int32))\n",
    "# print(np.fromiter(t_data[4],np.int32))\n",
    "# print(np.fromiter(t_data[5],np.int32))\n",
    "\n",
    "# Convert to numpy array - Use np.array(list)\n",
    "# for i in nparray - iterate through rows\n",
    "# for i in nparray.T - iterate through columns\n",
    "# Initialize np.zeros(5)\n",
    "\n",
    "# To view generator operators (Use list,tuples)\n",
    "# for i,j in enumerate(t_data):\n",
    "#     #lst_array[i] = np.array(list(j))\n",
    "#     lst_array[i] = np.fromiter(j,np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#GridSearchCV / Pipeline\n",
    "\n",
    "SEED = 35\n",
    "\n",
    "clf1 = RandomForestClassifier(max_depth=None,max_features='sqrt',min_samples_split=9,random_state=SEED)\n",
    "clf2 = ensemble.ExtraTreesClassifier(max_features='sqrt',min_samples_split=8,max_depth=None,random_state=SEED)\n",
    "clf3 = GradientBoostingClassifier(max_depth=20,min_samples_split=9,random_state=SEED,learning_rate=0.2,n_estimators=50)\n",
    "clf4 = linear_model.LogisticRegression(C=1,penalty='l2',class_weight='balanced')\n",
    "\n",
    "#estimators = [('mrf',RandomForestClassifier()),('etc',ExtraTreesClassifier()),('gbc',GradientBoostingClassifier())]\n",
    "#pipeline = Pipeline([('mrf',RandomForestClassifier())])\n",
    "\n",
    "eclf = ensemble.VotingClassifier(estimators=[('rfc',clf1),('etc',clf2),('gbc',clf3),('lr',clf4)],voting='soft')\n",
    "params = {\n",
    "    'rfc__n_estimators' : [50,100,500],\n",
    "    'etc__n_estimators' : [50,100,500],\n",
    "    'gbc__max_depth' : [5,20]\n",
    "}\n",
    "\n",
    "grid = grid_search.GridSearchCV(estimator=eclf,param_grid=params,scoring='roc_auc',n_jobs=-1)\n",
    "grid.fit(X,y)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)\n",
    "pred_grid = grid.predict_proba(X_test)\n",
    "print(pred_grid[:, 1])\n",
    "\n",
    "save_results(pred_grid[:, 1], \"submit_v1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scenario 1 : Will using the whole sparse array outperform using the normal\n",
    "# ET rf_data [ 0.86885664  0.859536    0.86248539]\n",
    "# ET Full Set [ 0.85228669  0.83864796  0.84169196]\n",
    "\n",
    "# tclf1 = ensemble.ExtraTreesClassifier(max_features='sqrt',max_depth=None,min_samples_split=9,n_estimators=50)\n",
    "# etsrf = cross_validation.cross_val_score(clf2,Xf,y,scoring='roc_auc',cv=3,n_jobs=-1)\n",
    "# etsf = cross_validation.cross_val_score(tclf1,X,y,scoring='roc_auc',cv=3,n_jobs=-1)\n",
    "# print(\"ET on Count Values\",etsrf)\n",
    "# print(\"ET Full Set\",etsf)\n",
    "\n",
    "# Scenario 2 : Performance with AdaBoost (Random Forest)\n",
    "# tclf1 = DecisionTreeClassifier(max_features='sqrt',max_depth=None)\n",
    "# tclf2 = RandomForestClassifier(max_depth=None,max_features='sqrt')\n",
    "# aclf1 = ensemble.AdaBoostClassifier(base_estimator=tclf1,n_estimators=500,learning_rate=1)\n",
    "# aclf2 = ensemble.AdaBoostClassifier(base_estimator=tclf2,n_estimators=500,learning_rate=1)\n",
    "# adadtc = cross_validation.cross_val_score(aclf1,X,y,scoring='roc_auc',cv=3,n_jobs=-1)\n",
    "# adarff = cross_validation.cross_val_score(aclf2,X,y,scoring='roc_auc',cv=3,n_jobs=-1)\n",
    "# adarfp = cross_validation.cross_val_score(aclf2,Xf,y,scoring='roc_auc',cv=3,n_jobs=-1)\n",
    "# print(\"AdaBoost on Decision Tree\",adadtc)\n",
    "# print(\"AdaBoost on Random Forest on Full Dataset\",adarff)\n",
    "# print(\"AdaBoost on Random Forest on Count Values\",adarfp)\n",
    "\n",
    "# Scenario 3 : Calibrated Random Forest vs uncalibrated\n",
    "# clf1_calib = CalibrationClassifierCV(base_estimator=clf1, cv=3, method='isotonic')\n",
    "# rfc_calib.train(Xf,y)\n",
    "# rfc = cross_validation.cross_val_score(clf1,Xf,y,scoring='roc_auc',cv=3,n_jobs=-1)\n",
    "# rfcc = cross_validation.cross_val_score(rfcc,Xf,y,scoring='roc_auc',cv=3,n_jobs=-1)\n",
    "\n",
    "# Scenario 5 : Ensemble with Logistic Regression \n",
    "# rs = cross_validation.ShuffleSplit(len(y),n_iter=1,test_size=.5, random_state=SEED)\n",
    "# for set1, set2 in rs:\n",
    "#     # Fit Set 1 to Set 2\n",
    "#     clf1.fit(Xf[set1],y[set1])\n",
    "#     clf2.fit(Xf[set1],y[set1])\n",
    "#     clf3.fit(Xf[set1],y[set1])\n",
    "#     clf4.fit(X[set1],y[set1])\n",
    "    \n",
    "#     pclf1 = clf1.predict_proba(Xf[set1])[:, 1]\n",
    "#     pclf2 = clf1.predict_proba(Xf[set1])[:, 1]\n",
    "#     pclf3 = clf1.predict_proba(Xf[set1])[:, 1]\n",
    "#     pclf4 = clf1.predict_proba(X[set1])[:, 1]\n",
    "    \n",
    "#     sclf1 = metrics.roc_auc_score(y[set2], pclf1)\n",
    "#     sclf2 = metrics.roc_auc_score(y[set2], pclf2)\n",
    "#     sclf3 = metrics.roc_auc_score(y[set2], pclf3)\n",
    "#     sclf4 = metrics.roc_auc_score(y[set2], pclf4)\n",
    "\n",
    "#     preds = np.hstack((pclf1,pclf2,pclf3,pclf4)).reshape(4,len(pclf1)).transpose()\n",
    "# #     preds[preds>0.9999999]=0.9999999\n",
    "# #     preds[preds<0.0000001]=0.0000001\n",
    "# #     preds = -np.log((1-preds)/preds)\n",
    "#     modelEN1 = linear_model.LogisticRegression()\n",
    "#     modelEN1.fit(preds, y[set2])\n",
    "#     print modelEN1.coef_\n",
    "    \n",
    "#     # Fit Set 2 to Set 1\n",
    "#     clf1.fit(Xf[set2],y[set2])\n",
    "#     clf2.fit(Xf[set2],y[set2])\n",
    "#     clf3.fit(Xf[set2],y[set2])\n",
    "#     clf4.fit(X[set2],y[set2])\n",
    "    \n",
    "#     pclf1 = clf1.predict_proba(Xf[set2])[:, 1]\n",
    "#     pclf2 = clf1.predict_proba(Xf[set2])[:, 1]\n",
    "#     pclf3 = clf1.predict_proba(Xf[set2])[:, 1]\n",
    "#     pclf4 = clf1.predict_proba(X[set2])[:, 1]\n",
    "    \n",
    "#     sclf1 = metrics.roc_auc_score(y[set1], pclf1)\n",
    "#     sclf2 = metrics.roc_auc_score(y[set1], pclf2)\n",
    "#     sclf3 = metrics.roc_auc_score(y[set1], pclf3)\n",
    "#     sclf4 = metrics.roc_auc_score(y[set1], pclf4)\n",
    "\n",
    "#     preds = np.hstack((pclf1,pclf2,pclf3,pclf4)).reshape(4,len(pclf1)).transpose()\n",
    "# #     preds[preds>0.9999999]=0.9999999\n",
    "# #     preds[preds<0.0000001]=0.0000001\n",
    "# #     preds = -np.log((1-preds)/preds)\n",
    "#     modelEN2 = linear_model.LogisticRegression()\n",
    "#     modelEN2.fit(preds, y[set1])\n",
    "#     print modelEN2.coef_\n",
    "\n",
    "#     coefRF = modelEN1.coef_[0][0] + modelEN2.coef_[0][0]\n",
    "#     coefXT = modelEN1.coef_[0][1] + modelEN2.coef_[0][1]\n",
    "#     coefGB = modelEN1.coef_[0][2] + modelEN2.coef_[0][2]\n",
    "#     coefLR = modelEN1.coef_[0][3] + modelEN2.coef_[0][3]\n",
    "\n",
    "# # Cross Validation\n",
    "# rscv = cross_validation.ShuffleSplit(len(y),n_iter=1,test_size=.5, random_state=SEED*2)\n",
    "# for set1, set2 in rscv:\n",
    "#     #Set 1\n",
    "#     clf1.fit(Xf[set1],y[set1])\n",
    "#     clf2.fit(Xf[set1],y[set1])\n",
    "#     clf3.fit(Xf[set1],y[set1])\n",
    "#     clf4.fit(X[set1],y[set1])\n",
    "    \n",
    "#     pclf1 = clf1.predict_proba(Xf[set2])[:, 1]\n",
    "#     pclf2 = clf1.predict_proba(Xf[set2])[:, 1]\n",
    "#     pclf3 = clf1.predict_proba(Xf[set2])[:, 1]\n",
    "#     pclf4 = clf1.predict_proba(X[set2])[:, 1]\n",
    "#     pclfe = coefRF * pclf1 + coefXT * pclf2 + coefGB * pclf3 + coefLR * pclf4\n",
    "    \n",
    "#     sclf1 = metrics.roc_auc_score(y[set2], pclf1)\n",
    "#     sclf2 = metrics.roc_auc_score(y[set2], pclf2)\n",
    "#     sclf3 = metrics.roc_auc_score(y[set2], pclf3)\n",
    "#     sclf4 = metrics.roc_auc_score(y[set2], pclf4)\n",
    "#     sclfe = metrics.roc_auc_score(y[set2], pclfe)\n",
    "#     #Set 2\n",
    "#     clf1.fit(Xf[set2],y[set2])\n",
    "#     clf2.fit(Xf[set2],y[set2])\n",
    "#     clf3.fit(Xf[set2],y[set2])\n",
    "#     clf4.fit(X[set2],y[set2])\n",
    "    \n",
    "#     pclf1 = clf1.predict_proba(Xf[set1])[:, 1]\n",
    "#     pclf2 = clf1.predict_proba(Xf[set1])[:, 1]\n",
    "#     pclf3 = clf1.predict_proba(Xf[set1])[:, 1]\n",
    "#     pclf4 = clf1.predict_proba(X[set1])[:, 1]\n",
    "#     pclfe = coefRF * pclf1 + coefXT * pclf2 + coefGB * pclf3 + coefLR * pclf4\n",
    "    \n",
    "#     sclf1 = metrics.roc_auc_score(y[set1], pclf1)\n",
    "#     sclf2 = metrics.roc_auc_score(y[set1], pclf2)\n",
    "#     sclf3 = metrics.roc_auc_score(y[set1], pclf3)\n",
    "#     sclf4 = metrics.roc_auc_score(y[set1], pclf4)\n",
    "#     sclfe = metrics.roc_auc_score(y[set1], pclfe)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Ensemble\n",
    "\n",
    "Xf = rf_data.values[:test_offset,6:18]\n",
    "Xf_test = rf_data.values[test_offset:,6:18]\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "clf1 = RandomForestClassifier(criterion='entropy',n_estimators=500,max_depth=None,max_features='sqrt',min_samples_split=9,random_state=SEED)\n",
    "clf2 = ensemble.ExtraTreesClassifier(criterion='entropy',n_estimators=500,max_features='sqrt',min_samples_split=8,max_depth=None,random_state=SEED)\n",
    "clf3 = GradientBoostingClassifier(max_depth=20,min_samples_split=9,random_state=SEED,learning_rate=0.2,n_estimators=50)\n",
    "clf4 = linear_model.LogisticRegression(C=1,penalty='l2',class_weight='balanced')\n",
    "\n",
    "## Does not support sparse array\n",
    "# rfs = cross_validation.cross_val_score(clf1,Xf,y,scoring='roc_auc',cv=3,n_jobs=-1)\n",
    "## Supports Sparse array\n",
    "# ets = cross_validation.cross_val_score(clf2,Xf,y,scoring='roc_auc',cv=3,n_jobs=-1)\n",
    "# gbs = cross_validation.cross_val_score(clf3,Xf,y,scoring='roc_auc',cv=3,n_jobs=-1)\n",
    "# lrs = cross_validation.cross_val_score(clf4,X,y,scoring='roc_auc',cv=3,n_jobs=-1)\n",
    "# print(\"RF\",rfs)\n",
    "# print(\"ET\",ets)\n",
    "# print(\"GB\",gbs)\n",
    "# print(\"LR\",lrs)\n",
    "\n",
    "\n",
    "# Scenario 4 : Averaging (Find Optimal Weights) // Incomplete!\n",
    "# Use Log Loss with Scipy.Optimize to find the suitable weights\n",
    "\n",
    "pave_coll = []\n",
    "pave_y = []\n",
    "rs = cross_validation.ShuffleSplit(len(y),n_iter=3,test_size=.2, random_state=SEED)\n",
    "for train, test in rs:\n",
    "    clf1.fit(Xf[train],y[train])\n",
    "    clf2.fit(Xf[train],y[train])\n",
    "    clf3.fit(Xf[train],y[train])\n",
    "    clf4.fit(X[train],y[train])\n",
    "    \n",
    "    pclf1 = clf1.predict_proba(Xf[test])[:, 1]\n",
    "    pclf2 = clf2.predict_proba(Xf[test])[:, 1]\n",
    "    pclf3 = clf3.predict_proba(Xf[test])[:, 1]\n",
    "    pclf4 = clf4.predict_proba(X[test])[:, 1]\n",
    "\n",
    "    pave = np.vstack((pclf1,pclf2,pclf3,pclf4)).transpose()\n",
    "    pave_coll.append(pave)\n",
    "    pave_y.append(y[test]) \n",
    "    \n",
    "pcoll = np.vstack(pave_coll)\n",
    "py = np.hstack(pave_y)\n",
    "\n",
    "# Optimize\n",
    "# https://www.kaggle.com/hsperr/otto-group-product-classification-challenge/finding-ensamble-weights\n",
    "def log_loss_func(weights):\n",
    "    ''' scipy minimize will pass the weights as a numpy array '''\n",
    "    prediction = np.asarray(np.mat(pcoll)*np.mat(weights.reshape(4,1)))\n",
    "    return metrics.roc_auc_score(py, prediction)\n",
    "    \n",
    "starting_values = np.array([0.25,0.25,0.25,0.25])\n",
    "# Equality constraint means that the constraint function result is to be zero whereas inequality means that it is to be non-negative\n",
    "cons = ({'type':'eq','fun':lambda w: 1-sum(w)})\n",
    "#our weights are bound between 0 and 1\n",
    "bounds = [(0,1)]*4\n",
    "res = minimize(log_loss_func, starting_values, method='SLSQP', bounds=bounds, constraints=cons)\n",
    "print('Ensamble Score: {best_score}'.format(best_score=res['fun']))\n",
    "print('Best Weights: {weights}'.format(weights=res['x']))\n",
    "    \n",
    "# === Predictions === #\n",
    "\n",
    "clf1.fit(Xf, y)\n",
    "clf2.fit(Xf, y)\n",
    "clf3.fit(Xf, y)\n",
    "clf4.fit(X, y)\n",
    "\n",
    "predsRF = clf1.predict_proba(Xf_test)[:, 1]\n",
    "predsET = clf2.predict_proba(Xf_test)[:, 1]\n",
    "predsGB = clf3.predict_proba(Xf_test)[:, 1]\n",
    "predsLR = clf4.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Scenario 4\n",
    "\n",
    "predsO = np.vstack((predsRF,predsET,predsGB,predsLR)).transpose()\n",
    "predsOF = np.asarray(np.mat(predsO) * np.mat(res['x'].reshape(4,1)))\n",
    "save_results(predsOF, \"submit_optimize.csv\") \n",
    "\n",
    "# predsC = (predsRF + predsET + predsGB + 2*predsLR)/5\n",
    "# save_results(predsC, \"submit_ave.csv\") #0.91042 - (predsRF + predsET + predsGB + 2*predsLR)/5\n",
    "# predsS = (np.amax(np.vstack((predsLR,predsGB,predsRF,predsET)),axis=0))\n",
    "# save_results(predsS, \"submit_vote.csv\") #0.86148\n",
    "\n",
    "# Scenario 5\n",
    "# predsE = coefRF * predsRF + coefXT * predsXT + coefGB * predsGB + coefLR * predsLR\n",
    "# save_results(predsE, \"submit_ensemble.csv\") \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., ...,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25],\n",
       "       [ 0.25],\n",
       "       [ 0.25],\n",
       "       [ 0.25]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sb.distplot(pcoll[:,1])\n",
    "# sb.distplot(pclf2)\n",
    "tx = np.array([[0,1,2,3],[4,5,6,7],[8,9,10,11]])\n",
    "# y = np.hstack((tx))\n",
    "# y\n",
    "weight = np.array([[0.25],[0.25],[0.25],[0.25]])\n",
    "# result = np.asarray(np.mat(tx) * np.mat(weight))\n",
    "weight.shape\n",
    "\n",
    "w = [0.25,0.25,0.25,0.25]\n",
    "rw = np.asarray(w).reshape((4,1))\n",
    "rw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predsS = (np.amax(np.vstack((predsLR,predsGB,predsRF,predsET)),axis=0))\n",
    "save_results(predsS, \"submit_v2.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC = Logistic Regression returns the probability that a certain input features would be in a certain class\n",
    "ROC curve visualizaes all possible thresholds\n",
    "Misclassification rate is error rate for a single threshold\n",
    "\n",
    "\n",
    "Attempt with original features only : CV : ... , Public : 0.88515, Private : 0.88205\n",
    "\n",
    "Attempt with original features + combination of 3 : CV : 0.886375 , Public : 0.90141, Private 0.89582 \n",
    "ExtraTreeClassifier = submit_etc.csv\n",
    "\n",
    "\n",
    "Attempt with original features + combination of 3 : CV : 0.886375 , Public : 0.90141, Private 0.89582 \n",
    "Logistic C=1, class_weight='balanced',penalty='l2' = submit_c3.csv\n",
    "\n",
    "Attempt with DTC selected features : CV :  0.886555 (threshold >0) , Public : , Private \n",
    "j>0.001 or 0 \n",
    "Logistic\n",
    "\n",
    "Attempt with Random Lasso  : CV : 0.886439   , Public : , Private \n",
    "j>0\n",
    "Logistic C=1, class_weight='balanced',penalty='l2' = submit_rl.csv\n",
    "\n",
    "Cheat Sheet from Kaggle, CV : 0.895952\n",
    "Logistic C=1, class_weight='balanced',penalty='l2' = submit_kc.csv - Private = 0.89872"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "te1 = np.array([1,2,30,4,5])\n",
    "te2 = np.array([11,7,8,9,10])\n",
    "te3 = np.array([3,12,13,14,15])\n",
    "teh = np.vstack((te1,te2,te3))\n",
    "print(teh)\n",
    "print(np.amax(teh,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "teh = np.hstack((te1,te2,te3)).reshape(3,5).transpose()\n",
    "print(teh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileObject = open(\"test.pickle\",'wb') \n",
    "pickle.dump(RandomForestClassifier,fileObject)   \n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "who_ls\n",
    "%reset_selective -f b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
