{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "db0a8d8c-7e97-4d52-a6bd-166cdbcbd1d9",
    "_uuid": "bbcef144213412551d9bec0430ebe0e7802bcbbe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv\n",
      "test.tsv\n",
      "train.tsv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import wordbatch \n",
    "from wordbatch.extractors import WordBag, WordHash\n",
    "from wordbatch.models import FTRL, FM_FTRL\n",
    "\n",
    "import time\n",
    "from datetime import datetime \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn_pandas import DataFrameMapper, cross_val_score\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "from scipy.sparse import csr_matrix, hstack, coo_matrix\n",
    "\n",
    "# set seed\n",
    "np.random.seed(123)\n",
    "start_time = time.time()\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "# Try wordbatch\n",
    "# Try RNN\n",
    "# Look at RMSLE Error Function\n",
    "# https://www.kaggle.com/valkling/mercari-rnn-2ridge-models-with-notes-0-42755\n",
    "# Combine both sets and do processing together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "0e0be440-f562-4b33-aafc-71929beb780e",
    "_uuid": "21f853dd205340121eddb123f5d713aaa0f311e4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/train.tsv',sep='\\t')\n",
    "test_df = pd.read_csv('../input/test.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "bee8c311-a1fd-4979-a257-d1af575da825",
    "_uuid": "b7c654041fdeacdaef23f578b95644715e6172c6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use to split the sets later\n",
    "nrow_test = len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "6b251d4c-e5d0-46c0-88d2-97d2fe8c2cf7",
    "_uuid": "750c5401f26ae43793fafce50c0d07198f3569b2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_df = pd.concat([train_df,test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "58b6b9fe-4789-4d18-b700-2acfd3736bec",
    "_uuid": "cd97ecee7d9d24b9c5eb157d3a342aaca14b1f21"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>item_description</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>test_id</th>\n",
       "      <th>train_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>3</td>\n",
       "      <td>No description yet</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Razer</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>3</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  brand_name                                      category_name  \\\n",
       "0        NaN                                  Men/Tops/T-shirts   \n",
       "1      Razer  Electronics/Computers & Tablets/Components & P...   \n",
       "\n",
       "   item_condition_id                                   item_description  \\\n",
       "0                  3                                 No description yet   \n",
       "1                  3  This keyboard is in great condition and works ...   \n",
       "\n",
       "                                  name  price  shipping  test_id  train_id  \n",
       "0  MLB Cincinnati Reds T Shirt Size XL   10.0         1      NaN       0.0  \n",
       "1     Razer BlackWidow Chroma Keyboard   52.0         0      NaN       1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "c4509c5c-8837-42e5-84cb-c1ef0a2525d8",
    "_uuid": "bc77ff8bcb17d906487541162a61ad5af6239b97",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get name and description lengths\n",
    "def wordCount(text):\n",
    "    try:\n",
    "        if text == 'No description yet':\n",
    "            return 0\n",
    "        else:\n",
    "            text = text.lower()\n",
    "            words = [w for w in text.split(\" \")]\n",
    "            return len(words)\n",
    "    except: \n",
    "        return 0\n",
    "full_df['desc_len'] = train_df['item_description'].apply(lambda x: wordCount(x))\n",
    "full_df['name_len'] = train_df['name'].apply(lambda x: wordCount(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "5ccffb5f-0ae8-4817-9099-09a00d9314c4",
    "_uuid": "740379f3d787a91bcc10029d9faeb71cffe98c88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling missing data...\n",
      "1    Electronics/Computers & Tablets/Components & P...\n",
      "1              Other/Office supplies/Shipping Supplies\n",
      "Name: category_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# split category name into 3 parts\n",
    "def split_cat(text):\n",
    "    try: return text.split(\"/\")\n",
    "    except: return (\"No Label\", \"No Label\", \"No Label\")\n",
    "    \n",
    "full_df['subcat_0'], full_df['subcat_1'], full_df['subcat_2'] = \\\n",
    "zip(*full_df['category_name'].apply(lambda x: split_cat(x)))\n",
    "\n",
    "# Filling missing values\n",
    "def fill_missing_values(df):\n",
    "    df.category_name.fillna(value=\"missing\", inplace=True)\n",
    "    df.brand_name.fillna(value=\"missing\", inplace=True)\n",
    "    df.item_description.fillna(value=\"missing\", inplace=True)\n",
    "    df.item_description.replace('No description yet',\"missing\", inplace=True)\n",
    "    return df\n",
    "\n",
    "print(\"Filling missing data...\")\n",
    "full_df = fill_missing_values(full_df)\n",
    "print(full_df.category_name[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "8b8746ed-1b65-40be-96de-e87975ce8831",
    "_uuid": "4f9fd2f8df47338eb07241bd4f3f5ae1a8137643"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "928207\n"
     ]
    }
   ],
   "source": [
    "all_brands = set(full_df['brand_name'].values)\n",
    "\n",
    "# Get missing brand name from name\n",
    "premissing = len(full_df.loc[full_df['brand_name'] == 'missing'])\n",
    "def brandfinder(line):\n",
    "    brand = line[0]\n",
    "    name = line[1]\n",
    "    namesplit = name.split(' ')\n",
    "    if brand == 'missing':\n",
    "        for x in namesplit:\n",
    "            if x in all_brands:\n",
    "                return name\n",
    "    if name in all_brands:\n",
    "        return name\n",
    "    return brand\n",
    "full_df['brand_name'] = train_df[['brand_name','name']].apply(brandfinder, axis = 1)\n",
    "found = premissing-len(full_df.loc[train_df['brand_name'] == 'missing'])\n",
    "print(found)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "8886d95a-3d4e-4d57-bd53-bf814b76f49a",
    "_uuid": "fde1716492ced542a18e6c8488d257dc2c8c6ed7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of brands 4823\n",
      "number of item condition 5\n",
      "number of cat1 11\n",
      "number of cat2 114\n",
      "number of cat3 883\n"
     ]
    }
   ],
   "source": [
    "print('number of brands', len(full_df.brand_name.unique()))\n",
    "print('number of item condition', len(full_df.item_condition_id.unique()))\n",
    "print('number of cat1', len(full_df.subcat_0.unique()))\n",
    "print('number of cat2', len(full_df.subcat_1.unique()))\n",
    "print('number of cat3', len(full_df.subcat_2.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "01d6b834-3887-4fc6-99be-f7e240f2f650",
    "_uuid": "77ebeee9d25278b39065cdf1c81c5da11583d125",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_df.brand_name.fillna(value=\"missing\", inplace=True)\n",
    "full_df[\"target\"] = np.log1p(full_df.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "8607fd62-66a4-4a06-9a0e-7e47ee8ca0e2",
    "_uuid": "d8716900f3313877d013d2cd9bf2433e33c3681e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    return u\" \".join(\n",
    "        [y for y in  text.lower().strip().split(\" \") if len(y) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "da4565eb-8a0a-4dfa-b276-2745574daff8",
    "_uuid": "a3ab4a1101f245928e948cd8a2a7af51dc957340"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize text\n",
      "Extract wordbags\n",
      "Normalize text\n",
      "Extract wordbags\n"
     ]
    }
   ],
   "source": [
    "# nm_tfidf = TfidfVectorizer(ngram_range=(1, 3),lowercase=True,max_df=0.95,min_df=10,max_features=1000)\n",
    "# X_name = nm_tfidf.fit_transform(full_df['name'].values)\n",
    "wb_nm = wordbatch.WordBatch(normalize_text, extractor=(WordBag, {\"hash_ngrams\": 2, \"hash_ngrams_weights\": [1.0, 1.0],\"hash_size\": 2 ** 28, \"norm\": \"l2\", \"tf\": 1.0,\"idf\": None}), procs=1)\n",
    "wb_nm.dictionary_freeze= True\n",
    "X_name = wb_nm.fit_transform(full_df['name'])\n",
    "\n",
    "# desc_tfidf = TfidfVectorizer(ngram_range=(1, 3),lowercase=True,max_df=0.95,min_df=10,max_features=1000)\n",
    "# X_desc = desc_tfidf.fit_transform(full_df['item_description'].values)\n",
    "wb_desc = wordbatch.WordBatch(normalize_text, extractor=(WordBag, {\"hash_ngrams\": 2, \"hash_ngrams_weights\": [1.0, 1.0],\"hash_size\": 2 ** 28, \"norm\": \"l2\", \"tf\": 1.0,\"idf\": None}), procs=1)\n",
    "wb_desc.dictionary_freeze= True\n",
    "X_desc = wb_desc.fit_transform(full_df['item_description'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "5088798a-2fd1-47b7-a0f8-c22e70201436",
    "_uuid": "dceff525cfde104f04684fb61833a3a8cf9e1a84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 3, 0, 7]), <1x14 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 1 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer(sparse_output=True)\n",
    "X_brand = lb.fit_transform(full_df['brand_name'])\n",
    "\n",
    "wb = CountVectorizer()\n",
    "X_category1 = wb.fit_transform(full_df['subcat_0'])\n",
    "X_category2 = wb.fit_transform(full_df['subcat_1'])\n",
    "X_category3 = wb.fit_transform(full_df['subcat_2'])\n",
    "X_others = full_df[['shipping','item_condition_id','desc_len','name_len']].values\n",
    "\n",
    "X_name.shape,X_desc.shape,X_category1.shape,X_category2.shape,X_category3.shape,X_others.shape\n",
    "X_others[0],X_category1[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "3d5f910b-0991-4172-9cff-fb10fdfc3970",
    "_uuid": "0ae0dc81f3d83a22012eadd51cd9b87e1491ae84",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge = np.hstack((X_name,X_desc,X_category1,X_category2,X_category3,X_others))\n",
    "merge = hstack((X_name,X_desc,X_brand,X_category1,X_category2,X_category3,csr_matrix(X_others))).tocsr()\n",
    "\n",
    "# only get columns where there is at least 1 element\n",
    "mask= np.where(merge.getnnz(axis=0) > 1)[0]\n",
    "merge = merge[:,mask]\n",
    "\n",
    "X_train = merge[:nrow_test]\n",
    "X_test = merge[nrow_test:]\n",
    "# y_train = full_df['target'].values\n",
    "y_train = np.array(full_df.iloc[:nrow_test,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "14bac30a-b0fc-4a52-abd3-f58acc5b23dc",
    "_uuid": "454003d008342b3610358bbe6b951857889b8696"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3302410"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a7275f1a-1fc6-47d4-98ad-e543fa7b9d9a",
    "_uuid": "a1a1b7c053bf99840e54b9a6b66525efdde61c7a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_ftrl = FTRL(alpha=0.01, beta=0.1, L1=0.00001, L2=1.0, D=merge.shape[1], iters=50, inv_link=\"identity\", threads=8)\n",
    "model_ftrl.fit(X_train, y_train)\n",
    "y_pred_ftrl = model_ftrl.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "076e8cb6-1304-47e5-9bcd-bb47d2b91ada",
    "_uuid": "871cc02350a447d9729f36b240387585b721074b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_fm_ftrl = FM_FTRL(alpha=0.01, beta=0.01, L1=0.00001, L2=0.1, D=merge.shape[1], alpha_fm=0.01, L2_fm=0.0, init_fm=0.01,D_fm=200, e_noise=0.0001, iters=15, inv_link=\"identity\", threads=8)\n",
    "model_fm_ftrl.fit(X_train, y_train)\n",
    "y_pred_fm_ftrl = model_fm_ftrl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "be22837c7a01639a14a10aad8f9062261c31ecb7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "# http://lightgbm.readthedocs.io/en/latest/Python-API.html\n",
    "X_train_lgb, X_valid_lgb, y_train_lgb, y_valid_lgb = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "d_train = lgb.Dataset(X_train_lgb, label=y_train_lgb)\n",
    "d_valid = lgb.Dataset(X_valid_lgb, label=y_valid_lgb)\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression', # 'binary'\n",
    "    'metric': 'rmse',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "\n",
    "clf = lgb.train(params, d_train, valid_sets=d_valid,num_boost_round=500,early_stopping_rounds=50)\n",
    "y_pred1=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5af39ba237b0098b4a7c4e42e86d4c8213a1abb7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_preds = (np.expm1(y_pred_ftrl) + np.expm1(y_pred_fm_ftrl))/2\n",
    "preds_df = pd.DataFrame(y_preds)\n",
    "preds_df.reset_index(inplace=True)\n",
    "preds_df.columns = ['test_id','price']\n",
    "preds_df.to_csv('ensemble_submit_1.csv',index=False)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1db2855-4725-4f44-9404-07f5c12525a1",
    "_uuid": "b65e8839f39ad19a47f21b55b24196a571157f51",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame(y_pred_ftrl)\n",
    "preds_df.reset_index(inplace=True)\n",
    "preds_df.columns = ['test_id','price']\n",
    "\n",
    "preds_df['price'] = preds_df.price.apply(lambda x:np.expm1(x))\n",
    "preds_df.to_csv('ftrl_submit_1.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7856cfb6-5791-4a5c-9772-28287344f2e8",
    "_uuid": "e29169d5126502b764e8f4c295018c2eddee585d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "11005bce-f14a-479f-83fd-fc574b2ef4c7",
    "_uuid": "0b32a327bfd8ba691c0b357234b31f9210b4a626",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try Xgboost , Lightgbm ,wordbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e6de27ef-1201-40f0-bea4-4cf948014055",
    "_uuid": "92e44e154800773d173f1ce313e5bd94427f30ab",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"Fitting Ridge model on training examples...\")\n",
    "# ridge_model = Ridge(\n",
    "#     solver='auto', fit_intercept=True, alpha=1.0,\n",
    "#     max_iter=100, normalize=False, tol=0.05, random_state = 1,\n",
    "# )\n",
    "# ridge_modelCV = RidgeCV(\n",
    "#     fit_intercept=True, alphas=[5.0],\n",
    "#     normalize=False, cv = 2, scoring='neg_mean_squared_error',\n",
    "# )\n",
    "# ridge_model.fit(X_train, Y_train)\n",
    "# ridge_modelCV.fit(X_train, Y_train)\n",
    "\n",
    "# Y_dev_preds_ridge = ridge_model.predict(X_dev)\n",
    "# Y_dev_preds_ridge = Y_dev_preds_ridge.reshape(-1, 1)\n",
    "# print(\"RMSL error on dev set:\", rmsle(Y_dev, Y_dev_preds_ridge))\n",
    "\n",
    "# Y_dev_preds_ridgeCV = ridge_modelCV.predict(X_dev)\n",
    "# Y_dev_preds_ridgeCV = Y_dev_preds_ridgeCV.reshape(-1, 1)\n",
    "# print(\"CV RMSL error on dev set:\", rmsle(Y_dev, Y_dev_preds_ridgeCV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1ded46e0-ee38-450a-b854-79f98ade8c58",
    "_uuid": "465d07aac1ff893cd54b1b4ab47ef71db25687d3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/anttttti/Wordbatch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
