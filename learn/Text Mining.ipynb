{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import nltk.stem\n",
    "import sklearn.datasets\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# f = open('textmine.pickle', 'wb')  \n",
    "# save = {\n",
    "#     'all_data': all_data,\n",
    "#     'train_data' : train_data,\n",
    "#     'test_data' : test_data\n",
    "#     }\n",
    "# pickle.dump(save,f)\n",
    "# f.close()\n",
    "\n",
    "\n",
    "with open(\"textmine.pickle\", 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  all_data = save['all_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(np.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = nltk.stem.SnowballStemmer('english')\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        #StemmedCountVectorizer will return CountVectorizer build_analyzer code\n",
    "        analyzer = super(TfidfVectorizer,self).build_analyzer()\n",
    "        return lambda doc: (s.stem(w) for w in analyzer(doc))\n",
    "    \n",
    "vectorizer = StemmedTfidfVectorizer(min_df=1,stop_words='english',decode_error='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "posts = [\"This is a toy post about machine learning. Actually, it contains not much interesting stuff.\", \n",
    "         \"Imaging databases can get huge.\",\n",
    "         \"Most imaging databases save images permanently.\",\n",
    "         \"Imaging databases store images.\",\n",
    "         \"Imaging databases store images. Imaging databases store images.Imaging databases store images.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['actual',\n",
       " 'contain',\n",
       " 'databas',\n",
       " 'huge',\n",
       " 'imag',\n",
       " 'interest',\n",
       " 'learn',\n",
       " 'machin',\n",
       " 'perman',\n",
       " 'post',\n",
       " 'save',\n",
       " 'store',\n",
       " 'stuff',\n",
       " 'toy']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = vectorizer.fit_transform(posts)\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.toarray()\n",
    "num_samples, num_features = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 14)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-0142d1d049d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mbest_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m300000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpost\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mpost_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdist_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost_vec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew_post_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "def dist_raw(v1,v2):\n",
    "    delta = v1-v2\n",
    "    return sp.linalg.norm(delta.toarray())\n",
    "# Distance Coefficients between Two Lists or Sets in The Python Papers Source Codes\n",
    "\n",
    "best_doc = None\n",
    "best_dist = 300000\n",
    "\n",
    "for i,post in enumerate(X_train):\n",
    "    post_vec = X_train.getrow(i)\n",
    "    d = dist_raw(post_vec,new_post_vec)\n",
    "    if d < best_dist:\n",
    "        best_dist = d\n",
    "        best_i = i\n",
    "print(\"Best Post is %i with dist=%.2f\"%(best_i,best_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data = sklearn.datasets.fetch_20newsgroups(subset='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "groups = ['comp.graphics', 'comp.os.ms-windows.misc','comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware','comp.windows.x', 'sci.space']\n",
    "train_data = sklearn.datasets.fetch_20newsgroups(subset='train',categories=groups)\n",
    "test_data = sklearn.datasets.fetch_20newsgroups(subset='test',categories=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = StemmedTfidfVectorizer(min_df=10,max_df=0.5,stop_words='english',decode_error='ignore')\n",
    "vectorized = vectorizer.fit_transform(train_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#samples: 3529, #features: 4712\n"
     ]
    }
   ],
   "source": [
    "num_samples, num_features = vectorized.shape\n",
    "print(\"#samples: %d, #features: %d\" % (num_samples,num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 5899.560\n",
      "Iteration  1, inertia 3218.298\n",
      "Iteration  2, inertia 3184.333\n",
      "Iteration  3, inertia 3164.867\n",
      "Iteration  4, inertia 3152.004\n",
      "Iteration  5, inertia 3143.111\n",
      "Iteration  6, inertia 3136.256\n",
      "Iteration  7, inertia 3129.325\n",
      "Iteration  8, inertia 3124.567\n",
      "Iteration  9, inertia 3121.900\n",
      "Iteration 10, inertia 3120.210\n",
      "Iteration 11, inertia 3118.627\n",
      "Iteration 12, inertia 3117.363\n",
      "Iteration 13, inertia 3116.811\n",
      "Iteration 14, inertia 3116.588\n",
      "Iteration 15, inertia 3116.417\n",
      "Iteration 16, inertia 3115.760\n",
      "Iteration 17, inertia 3115.374\n",
      "Iteration 18, inertia 3115.155\n",
      "Iteration 19, inertia 3114.949\n",
      "Iteration 20, inertia 3114.515\n",
      "Iteration 21, inertia 3113.937\n",
      "Iteration 22, inertia 3113.720\n",
      "Iteration 23, inertia 3113.548\n",
      "Iteration 24, inertia 3113.475\n",
      "Iteration 25, inertia 3113.447\n",
      "Converged at iteration 25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='random', max_iter=300, n_clusters=50, n_init=1,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=3, tol=0.0001,\n",
       "    verbose=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km = KMeans(n_clusters=50, init='random', n_init=1,verbose=1, random_state=3)\n",
    "km.fit(vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38 17 47 ..., 41 14 16]\n",
      "(3529,)\n",
      "[[ 0.          0.          0.         ...,  0.          0.          0.05115952]\n",
      " [ 0.00255397  0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.00585929  0.          0.         ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.07535044  0.         ...,  0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(km.labels_)\n",
    "print(km.labels_.shape)\n",
    "print(km.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_post = \"Disk drive problems. Hi, I have a problem with my hard disk. After 1 year it is working only sporadically now. I tried to format it, but now it doesn't boot any more.Any ideas? Thanks.\"\n",
    "new_post_vec = vectorizer.transform([new_post])\n",
    "new_post_label = km.predict(new_post_vec)[0]\n",
    "similar_indices = (km.labels_==new_post_label).nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "similar = []\n",
    "for i in similar_indices:\n",
    "    dist = sp.linalg.norm((new_post_vec - vectorized[i].toarray()))\n",
    "    similar.append((dist, train_data.data[i]))\n",
    "\n",
    "similar = sorted(similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0378441731334074, \"From: Thomas Dachsel <GERTHD@mvs.sas.com>\\nSubject: BOOT PROBLEM with IDE controller\\nNntp-Posting-Host: sdcmvs.mvs.sas.com\\nOrganization: SAS Institute Inc.\\nLines: 25\\n\\nHi,\\nI've got a Multi I/O card (IDE controller + serial/parallel\\ninterface) and two floppy drives (5 1/4, 3 1/2) and a\\nQuantum ProDrive 80AT connected to it.\\nI was able to format the hard disk, but I could not boot from\\nit. I can boot from drive A: (which disk drive does not matter)\\nbut if I remove the disk from drive A and press the reset switch,\\nthe LED of drive A: continues to glow, and the hard disk is\\nnot accessed at all.\\nI guess this must be a problem of either the Multi I/o card\\nor floppy disk drive settings (jumper configuration?)\\nDoes someone have any hint what could be the reason for it.\\nPlease reply by email to GERTHD@MVS.SAS.COM\\nThanks,\\nThomas\\n+-------------------------------------------------------------------+\\n| Thomas Dachsel                                                    |\\n| Internet: GERTHD@MVS.SAS.COM                                      |\\n| Fidonet:  Thomas_Dachsel@camel.fido.de (2:247/40)                 |\\n| Subnet:   dachsel@rnivh.rni.sub.org (UUCP in Germany, now active) |\\n| Phone:    +49 6221 4150 (work), +49 6203 12274 (home)             |\\n| Fax:      +49 6221 415101                                         |\\n| Snail:    SAS Institute GmbH, P.O.Box 105307, D-W-6900 Heidelberg |\\n| Tagline:  One bad sector can ruin a whole day...                  |\\n+-------------------------------------------------------------------+\\n\")\n",
      "(1.0494693076510362, \"From: rogntorb@idt.unit.no (Torbj|rn Rognes)\\nSubject: Adding int. hard disk drive to IIcx\\nKeywords: Mac IIcx, internal, hard disk drive, SCSI\\nReply-To: rogntorb@idt.unit.no (Torbj|rn Rognes)\\nOrganization: Div. of CS & Telematics, Norwegian Institute of Technology\\nLines: 32\\n\\nI haven't seen much info about how to add an extra internal disk to a\\nmac. We would like to try it, and I wonder if someone had some good\\nadvice.\\n\\nWe have a Mac IIcx with the original internal Quantum 40MB hard disk,\\nand an unusable floppy drive. We also have a new spare Connor 40MB\\ndisk which we would like to use. The idea is to replace the broken\\nfloppy drive with the new hard disk, but there seems to be some\\nproblems:\\n\\nThe internal SCSI cable and power cable inside the cx has only\\nconnectors for one single hard disk drive.\\n\\nIf I made a ribbon cable and a power cable with three connectors each\\n(1 for motherboard, 1 for each of the 2 disks), would it work?\\n\\nIs the IIcx able to supply the extra power to the extra disk?\\n\\nWhat about terminators? I suppose that i should remove the resistor\\npacks from the disk that is closest to the motherboard, but leave them\\ninstalled in the other disk.\\n\\nThe SCSI ID jumpers should also be changed so that the new disk gets\\nID #1. The old one should have ID #0.\\n\\nIt is no problem for us to remove the floppy drive, as we have an\\nexternal floppy that we can use if it won't boot of the hard disk.\\n\\nThank you!\\n\\n----------------------------------------------------------------------\\nTorbj|rn Rognes                            Email: rogntorb@idt.unit.no\\n\")\n",
      "(1.1063375279728889, 'From: im14u2c@camelot.bradley.edu (Joe Zbiciak)\\nSubject: Re: Booting from B drive\\nNntp-Posting-Host: camelot.bradley.edu\\nOrganization: Happy Campers USA\\nLines: 25\\n\\nIn <C5nvvx.ns@mts.mivj.ca.us> rpao@mts.mivj.ca.us (Roger C. Pao) writes:\\n[much discussion about switching 5.25\" and 3.5\" drives removed]\\n\\nAnother (albeit strange) option is using a program like 800 II\\n(available via anonymous FTP at many major sites), or FDFORMAT\\n(also available via anonymous FTP), that allows you to format\\n5.25HD disks to 1.44Meg, or 3.5\"HD disks to 1.2Meg (along with\\nmany MANY other formats!) so you can DISKCOPY (yes, the broken\\nMeSsy-DOS DISKCOPY!) the 5.25\" disks onto 3.5\" disks or vice\\nversa...  I use this techniques with \"NON-DOS\" self-booting \\ngame disks on my old Tandy 1000, and it works...  Another program\\nnamed Teledisk (shareware--available on many major BBS\\'s) will\\nalso make the weird format disks, provided you have 800 II\\nor FDFormat installed....  Some disks that won\\'t DISKCOPY\\nproperly can be readily Teledisk\\'d into the proper format...\\nAt least this is a software solution for a hardware/BIOS \\ndeficiency, eh? \\n\\n\\n--\\nJoseph Zbiciak                         im14u2c@camelot.bradley.edu\\n[====Disclaimer--If you believe any of this, check your head!====]\\n------------------------------------------------------------------\\n\\nNuke the Whales!\\n')\n"
     ]
    }
   ],
   "source": [
    "print(similar[0])\n",
    "print(similar[1])\n",
    "print(similar[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(245, 'From: SITUNAYA@IBM3090.BHAM.AC.UK\\nSubject: test....(sorry)\\nOrganization: The University of Birmingham, United Kingdom\\nLines: 1\\nNNTP-Posting-Host: ibm3090.bham.ac.uk\\n\\n==============================================================================\\n', 'comp.graphics')\n"
     ]
    }
   ],
   "source": [
    "post_group = zip(train_data.data, train_data.target)\n",
    "all = [(len(post[0]), post[0], train_data.target_names[post[1]]) for post in post_group]\n",
    "graphics = sorted([post for post in all if post[2]=='comp.graphics'])\n",
    "print(graphics[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['situnaya', 'ibm3090', 'bham', 'ac', 'uk', 'subject', 'test', 'sorri', 'organ', 'univers', 'birmingham', 'unit', 'kingdom', 'line', 'nntp', 'post', 'host', 'ibm3090', 'bham', 'ac', 'uk']\n"
     ]
    }
   ],
   "source": [
    "noise_post = graphics[5][1]\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "print(list(analyzer(noise_post)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "useful = set(analyzer(noise_post)).intersection(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ac',\n",
       " 'birmingham',\n",
       " 'host',\n",
       " 'kingdom',\n",
       " 'nntp',\n",
       " 'sorri',\n",
       " 'test',\n",
       " 'uk',\n",
       " 'unit',\n",
       " 'univers'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
