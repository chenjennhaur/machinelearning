{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Role Title and Role Code are similar based on pandas\n",
    "Instead of using hashing, can consider cantor(m,n) = 1/2 * (m+n)(m+n+1)+m. Beware of hash collision\n",
    "PCA / SVD are more suited for continuous values. For discrete variables, consider using MCA\n",
    "Step 1 : Generate 2 tuples / 3 tuples\n",
    "Step 2 : Feature Extraction - Using Genetic Algorithm / Greedy Algorithm\n",
    "Step 3 : Try using Stacked Classifier \n",
    "a) np.mean\n",
    "b) weighted mean\n",
    "c) jaccard score\n",
    "d) pass the results from each classifer into another RF / Linear Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pivottablejs import pivot_ui\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt  \n",
    "from ipywidgets import widgets\n",
    "import numpy as np\n",
    "from sklearn import (metrics, cross_validation, linear_model, preprocessing)\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from itertools import combinations\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sb.set(style=\"ticks\", color_codes=True)\n",
    "df = pd.read_csv('train.csv')\n",
    "dft = pd.read_csv('test.csv')\n",
    "#g = sb.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTION</th>\n",
       "      <th>RESOURCE</th>\n",
       "      <th>MGR_ID</th>\n",
       "      <th>ROLE_ROLLUP_1</th>\n",
       "      <th>ROLE_ROLLUP_2</th>\n",
       "      <th>ROLE_DEPTNAME</th>\n",
       "      <th>ROLE_TITLE</th>\n",
       "      <th>ROLE_FAMILY_DESC</th>\n",
       "      <th>ROLE_FAMILY</th>\n",
       "      <th>ROLE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39353</td>\n",
       "      <td>85475</td>\n",
       "      <td>117961</td>\n",
       "      <td>118300</td>\n",
       "      <td>123472</td>\n",
       "      <td>117905</td>\n",
       "      <td>117906</td>\n",
       "      <td>290919</td>\n",
       "      <td>117908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17183</td>\n",
       "      <td>1540</td>\n",
       "      <td>117961</td>\n",
       "      <td>118343</td>\n",
       "      <td>123125</td>\n",
       "      <td>118536</td>\n",
       "      <td>118536</td>\n",
       "      <td>308574</td>\n",
       "      <td>118539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>36724</td>\n",
       "      <td>14457</td>\n",
       "      <td>118219</td>\n",
       "      <td>118220</td>\n",
       "      <td>117884</td>\n",
       "      <td>117879</td>\n",
       "      <td>267952</td>\n",
       "      <td>19721</td>\n",
       "      <td>117880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>36135</td>\n",
       "      <td>5396</td>\n",
       "      <td>117961</td>\n",
       "      <td>118343</td>\n",
       "      <td>119993</td>\n",
       "      <td>118321</td>\n",
       "      <td>240983</td>\n",
       "      <td>290919</td>\n",
       "      <td>118322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>42680</td>\n",
       "      <td>5905</td>\n",
       "      <td>117929</td>\n",
       "      <td>117930</td>\n",
       "      <td>119569</td>\n",
       "      <td>119323</td>\n",
       "      <td>123932</td>\n",
       "      <td>19793</td>\n",
       "      <td>119325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACTION  RESOURCE  MGR_ID  ROLE_ROLLUP_1  ROLE_ROLLUP_2  ROLE_DEPTNAME  \\\n",
       "0       1     39353   85475         117961         118300         123472   \n",
       "1       1     17183    1540         117961         118343         123125   \n",
       "2       1     36724   14457         118219         118220         117884   \n",
       "3       1     36135    5396         117961         118343         119993   \n",
       "4       1     42680    5905         117929         117930         119569   \n",
       "\n",
       "   ROLE_TITLE  ROLE_FAMILY_DESC  ROLE_FAMILY  ROLE_CODE  \n",
       "0      117905            117906       290919     117908  \n",
       "1      118536            118536       308574     118539  \n",
       "2      117879            267952        19721     117880  \n",
       "3      118321            240983       290919     118322  \n",
       "4      119323            123932        19793     119325  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTION</th>\n",
       "      <th>RESOURCE</th>\n",
       "      <th>MGR_ID</th>\n",
       "      <th>ROLE_ROLLUP_1</th>\n",
       "      <th>ROLE_ROLLUP_2</th>\n",
       "      <th>ROLE_DEPTNAME</th>\n",
       "      <th>ROLE_TITLE</th>\n",
       "      <th>ROLE_FAMILY_DESC</th>\n",
       "      <th>ROLE_FAMILY</th>\n",
       "      <th>ROLE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32769</td>\n",
       "      <td>32769</td>\n",
       "      <td>32769</td>\n",
       "      <td>32769</td>\n",
       "      <td>32769</td>\n",
       "      <td>32769</td>\n",
       "      <td>32769</td>\n",
       "      <td>32769</td>\n",
       "      <td>32769</td>\n",
       "      <td>32769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>7518</td>\n",
       "      <td>4243</td>\n",
       "      <td>128</td>\n",
       "      <td>177</td>\n",
       "      <td>449</td>\n",
       "      <td>343</td>\n",
       "      <td>2358</td>\n",
       "      <td>67</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1</td>\n",
       "      <td>4675</td>\n",
       "      <td>770</td>\n",
       "      <td>117961</td>\n",
       "      <td>118300</td>\n",
       "      <td>117878</td>\n",
       "      <td>118321</td>\n",
       "      <td>117906</td>\n",
       "      <td>290919</td>\n",
       "      <td>118322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>30872</td>\n",
       "      <td>839</td>\n",
       "      <td>152</td>\n",
       "      <td>21407</td>\n",
       "      <td>4424</td>\n",
       "      <td>1135</td>\n",
       "      <td>4649</td>\n",
       "      <td>6896</td>\n",
       "      <td>10980</td>\n",
       "      <td>4649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACTION  RESOURCE  MGR_ID  ROLE_ROLLUP_1  ROLE_ROLLUP_2  ROLE_DEPTNAME  \\\n",
       "count    32769     32769   32769          32769          32769          32769   \n",
       "unique       2      7518    4243            128            177            449   \n",
       "top          1      4675     770         117961         118300         117878   \n",
       "freq     30872       839     152          21407           4424           1135   \n",
       "\n",
       "        ROLE_TITLE  ROLE_FAMILY_DESC  ROLE_FAMILY  ROLE_CODE  \n",
       "count        32769             32769        32769      32769  \n",
       "unique         343              2358           67        343  \n",
       "top         118321            117906       290919     118322  \n",
       "freq          4649              6896        10980       4649  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(df['RESOURCE'].value_counts())\n",
    "#df['RESOURCE'].plot.hist(bins=7518)\n",
    "\n",
    "#dfc = df.iloc[:,1:10] \n",
    "dfc = df.iloc[:,:]\n",
    "for col in df.columns:\n",
    "  dfc[col] = df[col].astype('category')\n",
    "\n",
    "dfc.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test = pd.pivot_table(dfc,index=['ROLE_TITLE','ROLE_CODE'],aggfunc='count',dropna=True)\n",
    "#dfc.pivot_table(index='ROLE_TITLE',aggfunc=lambda x:len(x.unique()))\n",
    "mult = {}\n",
    "for c in df.columns:\n",
    "    temp = df.pivot_table(index=c,aggfunc=lambda x:len(x.unique()),fill_value=0).apply(np.max)\n",
    "    mult[c] = temp\n",
    "\n",
    "multpd = pd.DataFrame(mult)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_results(predictions, filename):\n",
    "    \"\"\"Given a vector of predictions, save results in CSV format.\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"id,ACTION\\n\")\n",
    "        for i, pred in enumerate(predictions):\n",
    "            f.write(\"%d,%f\\n\" % (i + 1, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert from dataframe to np.array\n",
    "y = np.ravel(df.iloc[:,:1])\n",
    "X = df.iloc[:,1:9]\n",
    "X_test = dft.iloc[:,1:9].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3050 4440   21 ...,    4    7   65]\n",
      " [ 644  162   21 ...,   34   62   67]\n",
      " [2706 1679   50 ...,    0 2590    3]\n",
      " ..., \n",
      " [3031 1042   21 ...,   19   41   65]\n",
      " [ 102 1403   21 ...,   22    7   65]\n",
      " [4090  555   21 ...,   75  866   14]]\n"
     ]
    }
   ],
   "source": [
    "# #Simplify the encoding. Probably not essential. Could possibly improve performance\n",
    "# #Vertical Stacking is required so that all the features are captured. There might be some features in test set not in train set\n",
    "# data_all = np.vstack((X,X_test))\n",
    "# #data_all_t = data_all[1:10,:]\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# data_t = []\n",
    "# # To perform column wise operations, use Transpose function\n",
    "# for i in data_all.T:\n",
    "#     le.fit(i)\n",
    "#     #Find the index for where test starts and train ends. \n",
    "#     data_test.append(le.transform(i[1000:]))\n",
    "#     data_train.append(le.transform(i[1:1000])) \n",
    "# data_t = np.asarray(data_t).T\n",
    "# print(data_t)\n",
    "# #print(data_all_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get Combinations of 2 features    \n",
    "data = np.vstack((df.iloc[:,1:-1],dft.iloc[:,1:-1]))\n",
    "m,n = data.shape\n",
    "print(m,n)\n",
    "\n",
    "yc = combinations(range(n),2)\n",
    "# to view all the combinations\n",
    "list(yc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4)\n",
      "(0, 1)\n",
      "(0, 2)\n",
      "(0, 3)\n",
      "(1, 2)\n",
      "(1, 3)\n",
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "# #Code to help Visualize what the algorithm is doing \n",
    "# t_data = []\n",
    "# test_data = np.array([[1,2,3,4],[1,2,2,0],[1,2,3,4],[1,4,5,6],[2,3,4,5]])\n",
    "# print(test_data.shape)\n",
    "\n",
    "# #if the combination of categories are the same, they will be hashed to the same value. Eg 1 row with (0,1,0) will have same \n",
    "# #hash value of another row with (0,1,0)\n",
    "# for indices in combinations(range(4),2):\n",
    "#     t_data.append(hash(tuple(v)) for v in test_data[:,indices])\n",
    "#     #print(v for v in test_data[:,indices])\n",
    "#     print(indices)\n",
    "    \n",
    "# #Comparison 1 - Combinations are (0,1),(0,2),(0,3),(1,2),(1,3),(2,3)\n",
    "# # for v in test_data[:,(0,1)]:\n",
    "# #   print(hash(tuple(v)))\n",
    "\n",
    "# #Comparison 2 - t_data[0] corresponds to (0,1)\n",
    "# #tuple(t_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #tuple is used here so that the result is hashable\n",
    "# new_data = []\n",
    "# for indices in combinations(range(n),2):\n",
    "#     new_data.append(hash(tuple(v)) for v in data[:,indices])\n",
    "#     #(print(v) for v in data.iloc[:,indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 5 7 2 0 6]\n",
      " [5 5 4 4 1 0 4 1]\n",
      " [4 3 2 5 5 1 3 5]\n",
      " [6 4 0 0 4 5 2 2]\n",
      " [7 6 1 1 2 3 1 1]\n",
      " [2 7 2 5 8 4 6 3]\n",
      " [1 2 2 2 3 6 5 4]\n",
      " [3 0 2 6 6 7 7 0]\n",
      " [8 8 3 3 0 0 8 1]]\n",
      "[[ 17183   1540 117961 118343 123125 118536 118536 308574]\n",
      " [ 36724  14457 118219 118220 117884 117879 267952  19721]\n",
      " [ 36135   5396 117961 118343 119993 118321 240983 290919]\n",
      " [ 42680   5905 117929 117930 119569 119323 123932  19793]\n",
      " [ 45333  14561 117951 117952 118008 118568 118568  19721]\n",
      " [ 25993  17227 117961 118343 123476 118980 301534 118295]\n",
      " [ 19666   4209 117961 117969 118910 126820 269034 118638]\n",
      " [ 31246    783 117961 118413 120584 128230 302830   4673]\n",
      " [ 78766  56683 118079 118080 117878 117879 304519  19721]]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = preprocessing.OneHotEncoder()\n",
    "# we want to encode the category IDs encountered both in\n",
    "# the training and the test set, so we fit the encoder on both\n",
    "encoder.fit(np.vstack((X,X_test)))\n",
    "X = encoder.transform(X)\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[312154 311780 311179 286792 286793 311868 311868 308575]\n",
      "[      0  312154  623934  935113 1221905 1508698 1820566 2132434 2441009]\n"
     ]
    }
   ],
   "source": [
    "print(encoder.n_values_)\n",
    "print(encoder.feature_indices_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC (fold 1/10): 0.840287\n",
      "AUC (fold 2/10): 0.837616\n",
      "AUC (fold 3/10): 0.838619\n",
      "AUC (fold 4/10): 0.843097\n",
      "AUC (fold 5/10): 0.823374\n",
      "AUC (fold 6/10): 0.848091\n",
      "AUC (fold 7/10): 0.814234\n",
      "AUC (fold 8/10): 0.829486\n",
      "AUC (fold 9/10): 0.820575\n",
      "AUC (fold 10/10): 0.839104\n",
      "Mean AUC: 0.833448\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "mean_auc = 0.0\n",
    "\n",
    "n = 10  # repeat the CV procedure 10 times to get more precise results\n",
    "#model = linear_model.LogisticRegression(C=1)\n",
    "model = BernoulliNB(alpha=0.005)\n",
    "for i in range(n):\n",
    "    # for each iteration, randomly hold out 20% of the data as CV set\n",
    "    X_train, X_cv, y_train, y_cv = cross_validation.train_test_split(X, y, test_size=.20, random_state=i*SEED)\n",
    "\n",
    "    # if you want to perform feature selection / hyperparameter\n",
    "    # optimization, this is where you want to do it\n",
    "\n",
    "    # train model and make predictions\n",
    "    model.fit(X_train, y_train) \n",
    "    preds = model.predict_proba(X_cv)[:, 1]\n",
    "\n",
    "    # compute AUC metric for this CV fold\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_cv, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print(\"AUC (fold %d/%d): %f\" % (i + 1, n, roc_auc))\n",
    "    mean_auc += roc_auc\n",
    "\n",
    "print(\"Mean AUC: %f\" % (mean_auc/n))\n",
    "\n",
    "# === Predictions === #\n",
    "# When making predictions, retrain the model on the whole training set\n",
    "model.fit(X, y)\n",
    "preds = model.predict_proba(X_test)[:, 1]\n",
    "save_results(preds, \"submit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Numpy Operations\n",
    "# print(np.fromiter(t_data[0],np.int32))\n",
    "# print(np.fromiter(t_data[1],np.int32))\n",
    "# print(np.fromiter(t_data[2],np.int32))\n",
    "# print(np.fromiter(t_data[3],np.int32))\n",
    "# print(np.fromiter(t_data[4],np.int32))\n",
    "# print(np.fromiter(t_data[5],np.int32))\n",
    "\n",
    "# Convert to numpy array - Use np.array(list)\n",
    "# for i in nparray - iterate through rows\n",
    "# for i in nparray.T - iterate through columns\n",
    "# Initialize np.zeros(5)\n",
    "\n",
    "# To view generator operators (Use list,tuples)\n",
    "# for i,j in enumerate(t_data):\n",
    "#     #lst_array[i] = np.array(list(j))\n",
    "#     lst_array[i] = np.fromiter(j,np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC = Logistic Regression returns the probability that a certain input features would be in a certain class\n",
    "ROC curve visualizaes all possible thresholds\n",
    "Misclassification rate is error rate for a single threshold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
