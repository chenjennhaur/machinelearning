{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9d2dbdb3-6c74-4f96-9865-2951dfd653ce",
    "_uuid": "bb41ad86b25fecf332927b0c8f55dd710101e33f"
   },
   "source": [
    "# Improved LSTM baseline\n",
    "\n",
    "This kernel is a somewhat improved version of [Keras - Bidirectional LSTM baseline](https://www.kaggle.com/CVxTz/keras-bidirectional-lstm-baseline-lb-0-051) along with some additional documentation of the steps. (NB: this notebook has been re-run on the new test set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "2f9b7a76-8625-443d-811f-8f49781aef81",
    "_uuid": "598f965bc881cfe6605d92903b758778d400fa8b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, GlobalAveragePooling1D, Lambda\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(s):\n",
    "    \"\"\"\n",
    "    Given a text, cleans and normalizes it. Feel free to add your own stuff.\n",
    "    \"\"\"\n",
    "    s = s.lower()\n",
    "    # Replace ips\n",
    "    s = re.sub(r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}', ' _ip_ ', s)\n",
    "    # Isolate punctuation\n",
    "    s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\-\\\\\\/\\,])', r' \\1 ', s)\n",
    "    # Remove some special characters\n",
    "    s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
    "    # Replace numbers and symbols with language\n",
    "    s = s.replace('&', ' and ')\n",
    "    s = s.replace('@', ' at ')\n",
    "    s = s.replace('0', ' zero ')\n",
    "    s = s.replace('1', ' one ')\n",
    "    s = s.replace('2', ' two ')\n",
    "    s = s.replace('3', ' three ')\n",
    "    s = s.replace('4', ' four ')\n",
    "    s = s.replace('5', ' five ')\n",
    "    s = s.replace('6', ' six ')\n",
    "    s = s.replace('7', ' seven ')\n",
    "    s = s.replace('8', ' eight ')\n",
    "    s = s.replace('9', ' nine ')\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvBlockLayer(object):\n",
    "    \"\"\"\n",
    "    two layer ConvNet. Apply batch_norm and relu after each layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_shape, num_filters):\n",
    "        self.model = Sequential()\n",
    "        # first conv layer\n",
    "        self.model.add(Conv1D(filters=num_filters, kernel_size=3, strides=1, padding=\"same\", input_shape=input_shape))\n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(Activation('relu'))\n",
    "\n",
    "        # second conv layer\n",
    "        self.model.add(Conv1D(filters=num_filters, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(Activation('relu'))\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return self.model(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c297fa80-beea-464b-ac90-f380ebdb02fe",
    "_uuid": "d961885dfde18796893922f72ade1bf64456404e"
   },
   "source": [
    "We include the GloVe word vectors in our input files. To include these in your kernel, simple click 'input files' at the top of the notebook, and search 'glove' in the 'datasets' section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "66a6b5fd-93f0-4f95-ad62-3253815059ba",
    "_uuid": "729b0f0c2a02c678631b8c072d62ff46146a82ef",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'data/'\n",
    "EMBEDDING_FILE=f'wv/glove.6B.100d.txt'\n",
    "TRAIN_DATA_FILE=f'{path}train.csv'\n",
    "TEST_DATA_FILE=f'{path}test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "98f2b724-7d97-4da8-8b22-52164463a942",
    "_uuid": "b62d39216c8d00b3e6b78b825212fd190757dff9"
   },
   "source": [
    "Set some basic config parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "2807a0a5-2220-4af6-92d6-4a7100307de2",
    "_uuid": "d365d5f8d9292bb9bf57d21d6186f8b619cbe8c3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_size = 16 # char embed\n",
    "maxlen = 1024 # max number of words in a comment to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b3a8d783-95c2-4819-9897-1320e3295183",
    "_uuid": "4dd8a02e7ef983f10ec9315721c6dda2958024af"
   },
   "source": [
    "Read in our data and replace missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "ac2e165b-1f6e-4e69-8acf-5ad7674fafc3",
    "_uuid": "8ab6dad952c65e9afcf16e43c4043179ef288780",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(TRAIN_DATA_FILE)\n",
    "test = pd.read_csv(TEST_DATA_FILE)\n",
    "\n",
    "list_sentences_train = train[\"comment_text\"].fillna(\"_empty_\").values\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train[list_classes].values\n",
    "list_sentences_test = test[\"comment_text\"].fillna(\"_empty_\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.51447000e+05,   5.64800000e+03,   1.53200000e+03,\n",
       "          8.66000000e+02,   5.10000000e+01,   1.90000000e+01,\n",
       "          5.00000000e+00,   0.00000000e+00,   2.00000000e+00,\n",
       "          1.00000000e+00]),\n",
       " array([  1.00000000e+00,   2.28200000e+02,   4.55400000e+02,\n",
       "          6.82600000e+02,   9.09800000e+02,   1.13700000e+03,\n",
       "          1.36420000e+03,   1.59140000e+03,   1.81860000e+03,\n",
       "          2.04580000e+03,   2.27300000e+03]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/X+3qG8Cyota2wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb7bccd5978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train['comment_text'].apply(lambda x: len(x.split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# cachedStop =  stopwords.words('english')\n",
    "# pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')\n",
    "# def cleanwords(sent):\n",
    "#     return ' '.join([word.lower() for word in sent.lower().split() if word not in cachedStop ])\n",
    "    # return pattern.sub('', sent.lower())\n",
    "\n",
    "# def cleanchars(sent):\n",
    "#     return sent.translate(translator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "54a7a34e-6549-45f7-ada2-2173ff2ce5ea",
    "_uuid": "e8810c303980f41dbe0543e1c15d35acbdd8428f"
   },
   "source": [
    "Standard keras preprocessing, to turn each comment into a list of word indexes of equal length (with truncation or padding as needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "79afc0e9-b5f0-42a2-9257-a72458e91dbb",
    "_uuid": "c292c2830522bfe59d281ecac19f3a9415c07155",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = len(tokenizer.word_counts)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2336"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f8c4f6a3-3a19-40b1-ad31-6df2690bec8a",
    "_uuid": "e1cb77629e35c2b5b28288b4d6048a86dda04d78"
   },
   "source": [
    "Read the glove word vectors (space delimited strings) into a dictionary from word->vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "62acac54-0495-4a26-ab63-2520d05b3e19",
    "_uuid": "574c91e270add444a7bc8175440274bdd83b7173",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))+1\n",
    "# embedding_matrix = np.random.normal(0, 1, (nb_words, embed_size))\n",
    "# for word, i in word_index.items():\n",
    "#     if i >= max_features: continue # greater than max word features\n",
    "#     embedding_vector = embeddings_index.get(word) # out of word vocabulary\n",
    "#     if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f1aeec65-356e-4430-b99d-bb516ec90b09",
    "_uuid": "237345510bd2e664b5c6983a698d80bac2732bc4"
   },
   "source": [
    "Simple bidirectional LSTM with two fully connected layers. We add some dropout to the LSTM since even 2 epochs is enough to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf = [(64,2),(128,2),(256,2),(512,2)]\n",
    "nf[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(num_filters, num_classes, sequence_max_length=maxlen, num_quantized_chars=71, embedding_size=16, learning_rate=0.001, top_k=8, model_path=None):\n",
    "\n",
    "    inputs = Input(shape=(sequence_max_length, ), dtype='int32', name='inputs')\n",
    "\n",
    "    embedded_sent = Embedding(num_quantized_chars, embedding_size, input_length=sequence_max_length)(inputs)\n",
    "\n",
    "    # First conv layer\n",
    "    conv = Conv1D(filters=64, kernel_size=3, strides=2, padding=\"same\")(embedded_sent)\n",
    "\n",
    "    # Each ConvBlock with one MaxPooling Layer\n",
    "#     for i in range(len(num_filters)):\n",
    "#         conv = ConvBlockLayer(get_conv_shape(conv), num_filters[i])(conv)\n",
    "#         conv = MaxPooling1D(pool_size=3, strides=2, padding=\"same\")(conv)\n",
    "\n",
    "    for i in range(len(num_filters)):\n",
    "        for j in range(num_filters[i][1]):\n",
    "            conv = Conv1D(filters=num_filters[i][0], kernel_size=3, strides=1, padding=\"same\")(conv)\n",
    "            conv = BatchNormalization()(conv)\n",
    "            conv = Activation('relu')(conv)\n",
    "#         print(num_filters[0],num_filters[1])\n",
    "        conv = MaxPooling1D(pool_size=3, strides=2, padding=\"same\")(conv)\n",
    "    \n",
    "#     conv = GlobalAveragePooling1D()(conv)\n",
    "#     conv = GlobalMaxPool1D()(conv)\n",
    "    # k-max pooling (Finds values and indices of the k largest entries for the last dimension)\n",
    "    def _top_k(x):\n",
    "        x = tf.transpose(x, [0, 2, 1])\n",
    "        k_max = tf.nn.top_k(x, k=top_k)\n",
    "        return tf.reshape(k_max[0], (-1, num_filters[-1][0] * top_k))\n",
    "    k_max = Lambda(_top_k, output_shape=(num_filters[-1][0] * top_k,))(conv)\n",
    "\n",
    "    # 3 fully-connected layer with dropout regularization\n",
    "#     fc1 = Dropout(0.2)(Dense(4096, activation='relu', kernel_initializer='he_normal')(k_max))\n",
    "#     fc2 = Dropout(0.2)(Dense(2048, activation='relu', kernel_initializer='he_normal')(fc1))\n",
    "#     fc3 = Dense(num_classes, activation='sigmoid')(fc2)\n",
    "\n",
    "# 3 fully-connected layer \n",
    "    fc1 = Dense(4096, activation='relu', kernel_initializer='he_normal')(k_max)\n",
    "    fc2 = Dense(2048, activation='relu', kernel_initializer='he_normal')(fc1)\n",
    "    fc3 = Dense(num_classes, activation='sigmoid')(fc2)\n",
    "\n",
    "\n",
    "    # define optimizer - 10-15 epochs\n",
    "    sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=False)\n",
    "    model = Model(inputs=inputs, outputs=fc3)\n",
    "    model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    if model_path is not None:\n",
    "        model.load_weights(model_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters = [(64,4),(128,4),(256,4),(512,4)]\n",
    "# Try 10,10,4,4\n",
    "model = build_model(num_filters=num_filters, num_classes=6, embedding_size=embed_size, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "embedding_11 (Embedding)     (None, 1024, 16)          1136      \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 512, 64)           3136      \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 512, 64)           12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_113 (Bat (None, 512, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 512, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 512, 64)           12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_114 (Bat (None, 512, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 512, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 512, 64)           12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_115 (Bat (None, 512, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 512, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 512, 64)           12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_116 (Bat (None, 512, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 512, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 256, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 256, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_117 (Bat (None, 256, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 256, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 256, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_118 (Bat (None, 256, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 256, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 256, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_119 (Bat (None, 256, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 256, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_132 (Conv1D)          (None, 256, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_120 (Bat (None, 256, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 256, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 128, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 128, 256)          98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_121 (Bat (None, 128, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 128, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 128, 256)          196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_122 (Bat (None, 128, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 128, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 128, 256)          196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_123 (Bat (None, 128, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 128, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 128, 256)          196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_124 (Bat (None, 128, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 128, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 64, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 64, 512)           393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_125 (Bat (None, 64, 512)           2048      \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 64, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 64, 512)           786944    \n",
      "_________________________________________________________________\n",
      "batch_normalization_126 (Bat (None, 64, 512)           2048      \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 64, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 64, 512)           786944    \n",
      "_________________________________________________________________\n",
      "batch_normalization_127 (Bat (None, 64, 512)           2048      \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 64, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 64, 512)           786944    \n",
      "_________________________________________________________________\n",
      "batch_normalization_128 (Bat (None, 64, 512)           2048      \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 64, 512)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 32, 512)           0         \n",
      "_________________________________________________________________\n",
      "lambda_9 (Lambda)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2048)              8390656   \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 6)                 12294     \n",
      "=================================================================\n",
      "Total params: 28,869,558\n",
      "Trainable params: 28,861,878\n",
      "Non-trainable params: 7,680\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4a624b55-3720-42bc-ad5a-7cefc76d83f6",
    "_uuid": "e2a0e9ce12e1ff5ea102665e79de23df5caf5802"
   },
   "source": [
    "Now we're ready to fit out model! Use `validation_split` when not submitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_cell_guid": "333626f1-a838-4fea-af99-0c78f1ef5f5c",
    "_uuid": "c1558c6b2802fc632edc4510c074555a590efbd8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/1\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.1239 - acc: 0.9638 - val_loss: 0.1193 - val_acc: 0.9638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f81d9d5eb70>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_t, y, batch_size=128, epochs=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007408182206817179"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "lrate = 0.01 * math.exp(-0.1*3)\n",
    "lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/1\n",
      " 14336/143613 [=>............................] - ETA: 2:24 - loss: 0.1113 - acc: 0.9654"
     ]
    }
   ],
   "source": [
    "K.set_value(model.optimizer.lr, 0.007)\n",
    "model.fit(X_t, y, batch_size=128, epochs=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/2\n",
      "143613/143613 [==============================] - 98s 683us/step - loss: 0.0721 - acc: 0.9769 - val_loss: 0.0716 - val_acc: 0.9768\n",
      "Epoch 2/2\n",
      "143613/143613 [==============================] - 98s 686us/step - loss: 0.0669 - acc: 0.9781 - val_loss: 0.0725 - val_acc: 0.9771\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_t, y, batch_size=128, epochs=2, validation_split=0.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d6fa2ace-aa92-40cf-913f-a8f5d5a4b130",
    "_uuid": "3dbaa4d0c22271b8b0dc7e58bcad89ddc607beaf"
   },
   "source": [
    "And finally, get predictions for the test set and prepare a submission CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "_cell_guid": "28ce30e3-0f21-48e5-af3c-7e5512c9fbdc",
    "_uuid": "e59ad8a98ac5bb25a6bddd72718f3ed8a7fb52e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164/153164 [==============================] - 22s 144us/step\n"
     ]
    }
   ],
   "source": [
    "y_test = model.predict([X_te], batch_size=1024, verbose=1)\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission[list_classes] = y_test\n",
    "sample_submission.to_csv('vdcnn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample_submission.to_csv('base_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_submission = pd.read_csv('data/sample_submission.csv')\n",
    "# len(test_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Baseline Score\n",
    "# loss: 0.0417 - acc: 0.9840 - val_loss: 0.0451 - val_acc: 0.9829 --> AUC : 0.9787\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
